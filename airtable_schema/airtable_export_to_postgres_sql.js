#!/usr/bin/env node
require('./load_env');
/**
 * Script: airtable_export_to_postgres_sql.js
 * Version: 2026-01-25.4
 * =============================================================================
 *  Copyright © 2025 Dank Mushrooms, LLC
 *  Licensed under the GNU General Public License v3 (GPL-3.0-only)
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 3 of the License.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with this program. If not, see <https://www.gnu.org/licenses/>.
 * =============================================================================
 * Direct airtable-export -> Postgres artifacts generator.
 * Goals:
 *  - Create base tables for STORED fields only (no lookup/rollup/formula as physical columns)
 *  - Represent links:
 *      - singleRecordLink: <field>_id BIGINT (references other.nocopk)
 *      - multipleRecordLinks: junction table _m2m_<a>_<b>_<field>(<a>_id, <b>_id) with FKs
 *  - Provide "presentation" views v_<table> that add:
 *      - __table, __primary (best-effort from primaryFieldId)
 *      - link arrays for junction links
 *  - Emit CSV loader script (\copy) when AIRTABLE_EXPORT_DIR is provided (best-effort).
 *
 * Outputs into POSTGRES_OUT_DIR:
 *   001_tables.sql            Base tables with STORED fields only (no lookup/rollup/formula as physical cols)
 *   002_links.sql             Junction tables + FK constraints for multipleRecordLinks
 *   003_views.sql             v_<table> views with __table, __primary (best-effort) and link id arrays
 *   004_computed_views.sql    <-- now compiled from TABLES_DUMP_PATH when present
 *   010_load.sql + csv/*.csv  Relational CSV + loader (base tables + junction resolution via airtable_id)
 *
 * Notes:
 *  - We avoid relying on NocoDB meta APIs entirely.
 *  - multipleRecordLinks are exported into junction tables (CSV) and resolved by airtable_id -> nocopk during load.
 *  - singleRecordLink loading is NOT implemented yet (needs mapping logic similar to junctions); we currently skip.
 *  - rollup aggregation formula is not present in airtable-export output, so rollups are emitted as array_agg with TODO.
 * Usage:
 *   node airtable_export_to_postgres_sql.js
 *
 * Known limitations:
 *   - Airtable rollup aggregation formula is NOT present in the get-tables payload you provided,
 *     so rollups are emitted as array_agg(...) with TODO comments (same limitation as before).
 *   - Formula compiler is "best effort" for common Airtable functions used in this base (IF/AND/OR/NOT,
 *     string concat via &, LEFT/RIGHT/MID, DATETIME_FORMAT, RECORD_ID, CREATED_TIME). Unhandled functions
 *     become NULL and are annotated in SQL comments. 
 *
 * Env:
 *   AIRTABLE_SCHEMA_PATH=./_schema.json
 *   POSTGRES_SCHEMA=public
 *   POSTGRES_OUT_DIR=./pg_out
 *   AIRTABLE_EXPORT_DIR=./export     (optional; directory with per-table JSON exports)
 *   CREATE_VIEWS=true              (default true)
 *   BIGINT_PKS=true                 (default true; creates nocopk BIGSERIAL PK and stores airtable_id)
 */

const fs = require('fs');
const path = require('path');

function envBool(name, defVal) {
  const v = (process.env[name] ?? '').toString().trim();
  if (!v) return defVal;
  return /^true|1|yes|y$/i.test(v);
}

const AIRTABLE_EXPORT_DIR = process.env.AIRTABLE_EXPORT_DIR || '';
const AIRTABLE_SCHEMA_PATH = process.env.AIRTABLE_SCHEMA_PATH ||  path.join(AIRTABLE_EXPORT_DIR, '_schema.json');
const TABLES_DUMP_PATH = process.env.TABLES_DUMP_PATH || path.join(AIRTABLE_EXPORT_DIR, 'tables_dump.json');
const POSTGRES_SCHEMA = (process.env.POSTGRES_SCHEMA || 'public').toString();
const POSTGRES_OUT_DIR = process.env.POSTGRES_OUT_DIR || './pg_out';
const CREATE_VIEWS = envBool('CREATE_VIEWS', true);
const BIGINT_PKS = envBool('BIGINT_PKS', true);

function die(msg) { console.error('[ERROR]', msg); process.exit(1); }
function readJson(p) { return JSON.parse(fs.readFileSync(p, 'utf8')); }
function ensureDir(p) { fs.mkdirSync(p, { recursive: true }); }
function ident(name) { return '"' + String(name).replace(/"/g, '""') + '"'; }
function literalText(s) { return "'" + String(s).replace(/'/g, "''") + "'"; }
function slug(name) { return String(name).toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, ''); }
function sqlHeader() { return `-- Generated by airtable_export_to_postgres_sql_v3.js\n-- ${new Date().toISOString()}\n`; }

function pgTypeForField(f) {
  const t = f.type;
  if (t === 'checkbox') return 'boolean';
  if (t === 'number' || t === 'currency' || t === 'percent' || t === 'rating') return 'numeric';
  if (t === 'count') return 'bigint';
  if (t === 'date') return 'date';
  if (t === 'dateTime' || t === 'createdTime' || t === 'lastModifiedTime') return 'timestamp without time zone';
  if (t === 'duration') return 'numeric';
  if (t === 'phoneNumber' || t === 'email' || t === 'url' || t === 'barcode') return 'text';
  if (t === 'singleSelect' || t === 'multipleSelects') return 'text';
  if (t === 'multilineText' || t === 'richText' || t === 'singleLineText') return 'text';
  if (t === 'attachment' || t === 'multipleAttachments') return 'jsonb';
  if (t === 'multipleRecordLinks') return null;
  if (t === 'singleRecordLink') return 'bigint';
  if (t === 'lookup' || t === 'multipleLookupValues' || t === 'rollup' || t === 'formula') return null;
  if (t === 'autoNumber') return 'bigint';
  if (t === 'collaborator' || t === 'multipleCollaborators') return 'text';
  if (t === 'button') return null;
  if (t === 'aiText') return 'text';
  return 'text';
}

function isComputedType(type) { return ['lookup','multipleLookupValues','rollup','formula'].includes(type); }

function tableById(schema, tid) { return (schema.tables || []).find(t => t.id === tid); }
function findFieldById(table, fid) { return (table.fields || []).find(x => x.id === fid); }

function findTableFile(dir, tableName) {
  const tableSlug = slug(tableName);
  const candidates = [
    path.join(dir, `${tableSlug}.json`),
    path.join(dir, `${tableName}.json`),
    path.join(dir, `${tableName}.records.json`),
  ];
  return candidates.find(p => fs.existsSync(p)) || '';
}

function writeCsv(csvDir, relName, cols, rows) {
  const csvPath = path.join(csvDir, `${relName}.csv`);
  const esc = (v) => {
    if (v === null || v === undefined) return '';
    const s = String(v);
    if (/[",\n\r]/.test(s)) return '"' + s.replace(/"/g,'""') + '"';
    return s;
  };
  const lines = [];
  lines.push(cols.map(esc).join(','));
  for (const r of rows) lines.push(cols.map(c => esc(r[c])).join(','));
  fs.writeFileSync(csvPath, lines.join('\n'), 'utf8');
  return csvPath;
}

// ---------- Airtable formula compiler (best-effort) ----------

function stripWs(s) { return String(s || '').replace(/\r\n/g, '\n').trim(); }

function splitTopLevelArgs(s) {
  // splits "a, b, IF(...), 'x,y'" at commas not inside parens/quotes
  const args = [];
  let cur = '';
  let depth = 0;
  let inS = false, inD = false;
  for (let i=0;i<s.length;i++) {
    const ch = s[i];
    const prev = s[i-1];
    if (ch === "'" && !inD && prev !== '\\') inS = !inS;
    if (ch === '"' && !inS && prev !== '\\') inD = !inD;
    if (!inS && !inD) {
      if (ch === '(') depth++;
      else if (ch === ')') depth = Math.max(0, depth-1);
      else if (ch === ',' && depth === 0) {
        args.push(cur.trim()); cur=''; continue;
      }
    }
    cur += ch;
  }
  if (cur.trim()) args.push(cur.trim());
  return args;
}

function convertStringLiterals(expr) {
  // Airtable uses "double quotes" for strings; Postgres uses single quotes.
  // This is naive but works for your dump where strings are in double quotes.
  // We avoid touching already single-quoted strings.
  let out = '';
  let inS=false, inD=false;
  for (let i=0;i<expr.length;i++) {
    const ch=expr[i];
    const prev=expr[i-1];
    if (ch==="'" && !inD && prev!=="\\") { inS=!inS; out+=ch; continue; }
    if (ch=='"' && !inS && prev!=="\\") { inD=!inD; out += (inD ? "'" : "'"); continue; }
    out+=ch;
  }
  return out;
}

function mapDatetimeFormat(fmt) {
  // Very small mapping for patterns we saw (YYMMDD, YY, MM, DD, etc)
  // Airtable uses moment.js; Postgres uses to_char patterns.
  // We'll handle YYMMDD and a few tokens; otherwise pass through.
  const f = fmt.replace(/^'|'$/g,''); // strip quotes
  const map = {
    'YYMMDD': 'YYMMDD',
    'YY': 'YY',
    'YYYY': 'YYYY',
    'MM': 'MM',
    'DD': 'DD',
    'HH': 'HH24',
    'hh': 'HH12',
    'mm': 'MI',
  };
  return map[f] ? `'${map[f]}'` : `'${f}'`;
}

function compileFormulaExpr(raw, ctx) {
  // ctx: { qualifier: 'base'|'btbl', fieldIdToCol: Map, formulaByFieldId: Map(fieldId->formula string), compiling:Set }
  let expr = stripWs(raw);
  if (!expr) return { sql: 'NULL', notes: ['empty formula'] };

  // Convert line breaks to spaces
  expr = expr.replace(/\s+/g, ' ').trim();

  // Replace field references {fldXXXX} with qualifier."col"
  expr = expr.replace(/\{(fld[A-Za-z0-9]+)\}/g, (_m, fid) => {
    const col = ctx.fieldIdToCol.get(fid);
    if (!col) return 'NULL';
    return `${ctx.qualifier}.${ident(col)}`;
  });

  // Operators: & -> ||
  // Only replace & when not inside quotes
  {
    let out = '';
    let inS=false;
    for (let i=0;i<expr.length;i++) {
      const ch=expr[i];
      if (ch==="'" && expr[i-1]!=="\\") inS=!inS;
      if (!inS && ch==='&') out += '||';
      else out += ch;
    }
    expr = out;
  }

  // String literal conversion
  expr = convertStringLiterals(expr);

  // Function compiler (recursive) for a small set
  function compileFunc(e) {
    const m = /^([A-Z_]+)\((.*)\)$/.exec(e.trim());
    if (!m) return null;
    const fn = m[1];
    const inner = m[2];
    const args = splitTopLevelArgs(inner);

    const c = (x) => compileAny(x);

    if (fn === 'IF' && (args.length === 2 || args.length === 3)) {
      const cond = c(args[0]);
      const tVal = c(args[1]);
      const fVal = args.length === 3 ? c(args[2]) : 'NULL';
      return `CASE WHEN (${cond}) THEN (${tVal}) ELSE (${fVal}) END`;
    }
    if (fn === 'AND') return '(' + args.map(a => `(${c(a)})`).join(' AND ') + ')';
    if (fn === 'OR') return '(' + args.map(a => `(${c(a)})`).join(' OR ') + ')';
    if (fn === 'NOT' && args.length === 1) return `(NOT (${c(args[0])}))`;
    if (fn === 'RIGHT' && args.length === 2) return `RIGHT((${c(args[0])})::text, (${c(args[1])})::int)`;
    if (fn === 'LEFT' && args.length === 2) return `LEFT((${c(args[0])})::text, (${c(args[1])})::int)`;
    if (fn === 'MID' && (args.length === 3)) return `SUBSTRING((${c(args[0])})::text FROM (${c(args[1])})::int FOR (${c(args[2])})::int)`;
    if (fn === 'LEN' && args.length === 1) return `LENGTH((${c(args[0])})::text)`;
    if (fn === 'LOWER' && args.length === 1) return `LOWER((${c(args[0])})::text)`;
    if (fn === 'UPPER' && args.length === 1) return `UPPER((${c(args[0])})::text)`;
    if (fn === 'VALUE' && args.length === 1) return `NULLIF((${c(args[0])})::text,'')::numeric`;
    if (fn === 'ROUND' && (args.length === 1 || args.length === 2)) {
      const n = c(args[0]);
      const d = args.length===2 ? c(args[1]) : '0';
      return `ROUND((${n})::numeric, (${d})::int)`;
    }
    if (fn === 'DATETIME_FORMAT' && args.length >= 2) {
      const dt = c(args[0]);
      const fmt = mapDatetimeFormat(args[1]);
      return `to_char((${dt})::timestamp, ${fmt})`;
    }
    if (fn === 'CREATED_TIME' && args.length === 0) return `${ctx.qualifier}.${ident('nc_created_at')}`;
    if (fn === 'RECORD_ID' && args.length === 0) return `${ctx.qualifier}.${ident('airtable_id')}`;
    if (fn === 'BLANK' && args.length === 0) return `''::text`;

    return null;
  }

  function compileAny(e) {
    const ee = e.trim();
    // if it's a function call at the top-level, compile it
    const compiled = compileFunc(ee);
    if (compiled) return compiled;
    // parentheses wrapping
    if (ee.startsWith('(') && ee.endsWith(')')) {
      // keep
      return `(${compileAny(ee.slice(1,-1))})`;
    }
    return ee;
  }

  const sql = compileAny(expr);
  // If it still contains unknown Airtable functions (uppercase followed by '('), we bail to NULL to keep view valid.
  if (/[A-Z_]+\(/.test(sql)) {
    return { sql: 'NULL', notes: ['unsupported function(s) in formula'] };
  }
  return { sql, notes: [] };
}

// ---------- Main generator ----------

function main() {
  if (!fs.existsSync(AIRTABLE_SCHEMA_PATH)) die(`Missing AIRTABLE_SCHEMA_PATH: ${AIRTABLE_SCHEMA_PATH}`);
  const exportSchema = readJson(AIRTABLE_SCHEMA_PATH);
  const exportTables = exportSchema.tables || [];
  if (!exportTables.length) die('export/_schema.json has no tables');

  let tablesDump = null;
  if (fs.existsSync(TABLES_DUMP_PATH)) {
    tablesDump = readJson(TABLES_DUMP_PATH);
    if (!tablesDump.tables || !Array.isArray(tablesDump.tables)) tablesDump = null;
  }

  // Use tablesDump for computed + primary if available; otherwise fall back to export schema
  const schema = tablesDump || exportSchema;
  const tables = schema.tables || [];

  ensureDir(POSTGRES_OUT_DIR);

  // FieldId maps and fieldName->id maps
  const tableFieldById = new Map(); // tableId -> Map(fieldId -> field)
  const tableFieldIdToCol = new Map(); // tableSlug -> Map(fieldId -> colSlug)
  const physicalColsByTableSlug = new Map();

  for (const t of tables) {
    const m = new Map();
    const m2 = new Map();
    for (const f of (t.fields || [])) {
      m.set(f.id, f);
      m2.set(f.id, slug(f.name));
    }
    tableFieldById.set(t.id, m);
    tableFieldIdToCol.set(slug(t.name), m2);
  }

  // Junctions: {jn, a, b, aCol, bCol, linkFieldSlug, linkFieldId}
  const junctions = [];

  // 001_tables.sql uses export schema (stored fields are same)
  let ddl = sqlHeader();
  ddl = `-- Requires extension pgcrypto for gen_random_uuid()\nCREATE EXTENSION IF NOT EXISTS pgcrypto;\n\n` + ddl;
  ddl += `BEGIN;\nCREATE SCHEMA IF NOT EXISTS ${ident(POSTGRES_SCHEMA)};\n`;

  for (const t of exportTables) {
    const tn = slug(t.name);
    const cols = [];
    const physical = new Set();

    if (BIGINT_PKS) { cols.push(`${ident('nocopk')} BIGSERIAL PRIMARY KEY`); physical.add('nocopk'); }
    else { cols.push(`${ident('airtable_id')} text PRIMARY KEY`); physical.add('airtable_id'); }

    cols.push(`${ident('nocouuid')} uuid DEFAULT gen_random_uuid()`); physical.add('nocouuid');
    cols.push(`${ident('airtable_id')} text UNIQUE`); physical.add('airtable_id');
    cols.push(`${ident('nc_created_at')} timestamp without time zone DEFAULT now()`); physical.add('nc_created_at');
    cols.push(`${ident('nc_updated_at')} timestamp without time zone DEFAULT now()`); physical.add('nc_updated_at');

    const reserved = new Set(['nocopk','nocouuid','airtable_id','nc_created_at','nc_updated_at']);

    for (const f of (t.fields || [])) {
      if (isComputedType(f.type)) continue;
      if (f.type === 'multipleRecordLinks') continue;
      if (f.type === 'button') continue;

      const baseName = slug(f.name);
      if (!baseName || reserved.has(baseName)) continue;

      if (f.type === 'singleRecordLink') {
        cols.push(`${ident(baseName + '_id')} bigint`);
        physical.add(baseName + '_id');
        continue;
      }

      const typ = pgTypeForField(f) || 'text';
      cols.push(`${ident(baseName)} ${typ}`);
      physical.add(baseName);
    }

    physicalColsByTableSlug.set(tn, physical);

    ddl += `\nCREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(tn)} (\n  ${cols.join(',\n  ')}\n);\n`;
  }
  ddl += `COMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '001_tables.sql'), ddl, 'utf8');

  // 002_links.sql derived from authoritative schema (tablesDump has complete links)
  let linksSql = sqlHeader();
  linksSql += `BEGIN;\n`;
  for (const t of tables) {
    const a = slug(t.name);
    for (const f of (t.fields || [])) {
      if (f.type !== 'multipleRecordLinks') continue;
      const linkedTableId = f.options && f.options.linkedTableId;
      if (!linkedTableId) continue;
      const other = tableById(schema, linkedTableId);
      if (!other) continue;
      const b = slug(other.name);

      const linkFieldSlug = slug(f.name) || 'link';
      const jn = `_m2m_${a}_${b}_${linkFieldSlug}`;
      const aCol = `${a}_id`;
      const bCol = (a === b) ? `${b}1_id` : `${b}_id`;

      junctions.push({ jn, a, b, aCol, bCol, linkFieldSlug, linkFieldId: f.id });

      linksSql += `\nCREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(jn)} (\n  ${ident(aCol)} bigint NOT NULL,\n  ${ident(bCol)} bigint NOT NULL\n);\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + aCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(aCol)});\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + bCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(bCol)});\n`;
      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)}\n  ADD CONSTRAINT ${ident(jn + '_' + aCol + '_fk')} FOREIGN KEY (${ident(aCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(a)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;
      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)}\n  ADD CONSTRAINT ${ident(jn + '_' + bCol + '_fk')} FOREIGN KEY (${ident(bCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(b)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;
    }
  }
  linksSql += `\nCOMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '002_links.sql'), linksSql, 'utf8');

  // 003_views.sql
  if (CREATE_VIEWS) {
    let vsql = sqlHeader();
    vsql += `BEGIN;\n`;
    for (const t of exportTables) vsql += `DROP VIEW IF EXISTS ${ident(POSTGRES_SCHEMA)}.${ident('v_' + slug(t.name))} CASCADE;\n`;
    vsql += '\n';

    for (const t of exportTables) {
      const a = slug(t.name);

      // primary field from tablesDump if present, else export schema
      const td = tablesDump ? tableById(tablesDump, t.id) : null;
      const pvId = (td && td.primaryFieldId) ? td.primaryFieldId : (t.primaryFieldId || null);
      const pvField = pvId ? (td ? findFieldById(td, pvId) : findFieldById(t, pvId)) : null;

      const pvSlug = pvField ? slug(pvField.name) : null;
      let primaryExpr = `t.${ident('nocopk')}::text`;
      if (pvField && !isComputedType(pvField.type) && pvField.type !== 'multipleRecordLinks') {
        if (pvField.type === 'singleRecordLink') primaryExpr = `COALESCE(t.${ident(pvSlug + '_id')}::text, t.${ident('nocopk')}::text)`;
        else primaryExpr = `COALESCE(t.${ident(pvSlug)}::text, t.${ident('nocopk')}::text)`;
      }

      const linkCols = [];
      for (const j of junctions.filter(x => x.a === a)) {
        const alias = `${a}__${j.b}__${j.linkFieldSlug}__ids`;
        linkCols.push(
          `(SELECT COALESCE(array_agg(j.${ident(j.bCol)} ORDER BY j.${ident(j.bCol)}), '{}'::bigint[]) ` +
          `FROM ${ident(POSTGRES_SCHEMA)}.${ident(j.jn)} j WHERE j.${ident(j.aCol)} = t.${ident('nocopk')}) AS ${ident(alias)}`
        );
      }

      vsql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)} AS\nSELECT\n  t.*,\n  ${literalText(`${POSTGRES_SCHEMA}.${a}`)}::text AS __table,\n  ${primaryExpr} AS __primary`;
      if (linkCols.length) vsql += `,\n  ${linkCols.join(',\n  ')}`;
      vsql += `\nFROM ${ident(POSTGRES_SCHEMA)}.${ident(a)} t;\n\n`;
    }

    vsql += `COMMIT;\n`;
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '003_views.sql'), vsql, 'utf8');
  }

  // 004_computed_views.sql compiled from tablesDump (authoritative)
  {
    let csql = sqlHeader();
    csql += `BEGIN;\n`;
    for (const t of exportTables) csql += `DROP VIEW IF EXISTS ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + slug(t.name))} CASCADE;\n`;
    csql += '\n';

    // Pre-index formula strings by table and field id
    const formulaByTableId = new Map(); // tableId -> Map(fieldId -> formula)
    for (const t of (tablesDump ? tablesDump.tables : [])) {
      const m = new Map();
      for (const f of (t.fields || [])) {
        if (f.type === 'formula' && f.options && f.options.formula) m.set(f.id, f.options.formula);
      }
      formulaByTableId.set(t.id, m);
    }

    // Memo for compiled formulas per table/field for base qualifier
    const compiledFormulaMemo = new Map(); // key `${tableSlug}:${fieldId}:${qual}` -> sql

    function compileFormulaFor(tableObj, fieldObj, qualifier) {
      const key = `${slug(tableObj.name)}:${fieldObj.id}:${qualifier}`;
      if (compiledFormulaMemo.has(key)) return compiledFormulaMemo.get(key);

      const map = tableFieldIdToCol.get(slug(tableObj.name)) || new Map();
      const ctx = {
        qualifier,
        fieldIdToCol: map,
      };
      const { sql } = compileFormulaExpr(fieldObj.options.formula, ctx);
      compiledFormulaMemo.set(key, sql);
      return sql;
    }

    for (const t of exportTables) {
      const a = slug(t.name);
      const td = tablesDump ? tableById(tablesDump, t.id) : null;
      const fields = td ? (td.fields || []) : [];
      const computed = fields.filter(f => isComputedType(f.type));

      if (!computed.length) {
        csql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + a)} AS SELECT * FROM ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)};\n\n`;
        continue;
      }

      const exprs = [];
      for (const f of computed) {
        const outAlias = slug(f.name) || 'computed';
        const outCol = ident(outAlias);

        if (f.type === 'formula') {
          const compiled = compileFormulaFor(td, f, 'base');
          if (compiled === 'NULL') csql += `-- TODO(formula): ${td.name}.${f.name} (unsupported)\n`;
          exprs.push(`(${compiled}) AS ${outCol}`);
          continue;
        }

        if (f.type === 'lookup' || f.type === 'multipleLookupValues' || f.type === 'rollup') {
          const opts = f.options || {};
          const linkFieldId = opts.recordLinkFieldId;
          const targetFieldId = opts.fieldIdInLinkedTable;
          if (!linkFieldId || !targetFieldId) {
            exprs.push(`'{}'::text[] AS ${outCol}`);
            continue;
          }

          const linkField = findFieldById(td, linkFieldId);
          if (!linkField || linkField.type !== 'multipleRecordLinks' || !linkField.options || !linkField.options.linkedTableId) {
            exprs.push(`'{}'::text[] AS ${outCol}`);
            continue;
          }

          const other = tableById(tablesDump, linkField.options.linkedTableId);
          if (!other) { exprs.push(`'{}'::text[] AS ${outCol}`); continue; }
          const b = slug(other.name);

          const otherField = findFieldById(other, targetFieldId);
          if (!otherField) { exprs.push(`'{}'::text[] AS ${outCol}`); continue; }

          // Determine target expression: physical column OR compiled formula
          let targetExpr = null;
          const physicalCols = physicalColsByTableSlug.get(b) || new Set();
          const targetSlug = slug(otherField.name);

          if (otherField.type === 'formula' && otherField.options && otherField.options.formula) {
            targetExpr = compileFormulaFor(other, otherField, 'btbl');
          } else if (physicalCols.has(targetSlug)) {
            targetExpr = `btbl.${ident(targetSlug)}::text`;
          } else {
            // computed-on-computed (lookup -> lookup/rollup) not supported yet
            targetExpr = null;
          }

          if (!targetExpr || targetExpr === 'NULL') {
            exprs.push(`'{}'::text[] AS ${outCol}`);
            continue;
          }

          const linkFieldSlug = slug(linkField.name) || 'link';
          const jn = `_m2m_${a}_${b}_${linkFieldSlug}`;
          const aCol = `${a}_id`;
          const bCol = (a === b) ? `${b}1_id` : `${b}_id`;

          if (f.type === 'rollup') {
            csql += `-- TODO(rollup): ${td.name}.${f.name} (Airtable rollup aggregation formula not present in tables_dump)\n`;
          }

          // For now: both lookup and rollup emit text[] of values in linked records.
          const expr =
            `(SELECT COALESCE(` +
            `array_agg((${targetExpr}) ORDER BY (${targetExpr})) FILTER (WHERE (${targetExpr}) IS NOT NULL), ` +
            `'{}'::text[]) ` +
            `FROM ${ident(POSTGRES_SCHEMA)}.${ident(jn)} j ` +
            `JOIN ${ident(POSTGRES_SCHEMA)}.${ident(b)} btbl ON btbl.nocopk = j.${ident(bCol)} ` +
            `WHERE j.${ident(aCol)} = base.nocopk) AS ${outCol}`;

          exprs.push(expr);
          continue;
        }

        // default
        exprs.push(`NULL AS ${outCol}`);
      }

      csql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + a)} AS\n`;
      csql += `SELECT base.*,\n  ${exprs.join(',\n  ')}\n`;
      csql += `FROM ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)} base;\n\n`;
    }

    csql += `COMMIT;\n`;
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '004_computed_views.sql'), csql, 'utf8');
  }

  // 010_load.sql + csv/*.csv (host-run \copy)
  if (AIRTABLE_EXPORT_DIR && fs.existsSync(AIRTABLE_EXPORT_DIR)) {
    const csvDir = path.join(POSTGRES_OUT_DIR, 'csv');
    ensureDir(csvDir);

    const loadSql = [];
    loadSql.push(sqlHeader());
    loadSql.push('\\set ON_ERROR_STOP on\n');
    loadSql.push("\\set basedir '.'\n");
    loadSql.push('BEGIN;\n');
    loadSql.push(`SET search_path TO ${ident(POSTGRES_SCHEMA)};\n`);

    for (const t of exportTables) {
      const tableName = t.name;
      const tableSlug = slug(tableName);
      const fp = findTableFile(AIRTABLE_EXPORT_DIR, tableName);
      if (!fp) continue;

      const data = readJson(fp);
      const rowsRaw = Array.isArray(data) ? data : (data.records || data.rows || []);
      if (!Array.isArray(rowsRaw) || rowsRaw.length === 0) continue;

      const storedFields = (t.fields || []).filter(f =>
        !isComputedType(f.type) &&
        f.type !== 'multipleRecordLinks' &&
        f.type !== 'singleRecordLink' &&
        f.type !== 'button'
      );
      const storedColSlugs = storedFields.map(f => slug(f.name)).filter(Boolean);
      const cols = ['airtable_id', ...storedColSlugs];

      const rows = rowsRaw.map(r => {
        const out = {};
        const airtableId = r.id || r.airtable_id || r.recordId || null;
        if (!airtableId) return null;
        out.airtable_id = airtableId;
        const fieldsObj = (r.fields && typeof r.fields === 'object') ? r.fields : r;
        for (const f of storedFields) {
          const kk = slug(f.name);
          let v = fieldsObj[f.name];
          if (v === undefined) continue;
          if (v && typeof v === 'object') v = JSON.stringify(v);
          out[kk] = v;
        }
        for (const c of cols) if (!(c in out)) out[c] = '';
        return out;
      }).filter(Boolean);

      if (!rows.length) continue;

      const csvPath = writeCsv(csvDir, tableSlug, cols, rows);
      const rel = path.relative(POSTGRES_OUT_DIR, csvPath).replace(/\\/g,'/');
      loadSql.push(`\\copy ${ident(tableSlug)}(${cols.map(ident).join(',')}) FROM :'basedir'/'${rel}' WITH (FORMAT csv, HEADER true);\n`);
    }

    // Junction CSVs are still derived from export record JSON
    for (const t of exportTables) {
      const aName = t.name;
      const a = slug(aName);
      const fp = findTableFile(AIRTABLE_EXPORT_DIR, aName);
      if (!fp) continue;

      const data = readJson(fp);
      const rowsRaw = Array.isArray(data) ? data : (data.records || data.rows || []);
      if (!Array.isArray(rowsRaw) || rowsRaw.length === 0) continue;

      const linkFields = (t.fields || []).filter(f => f.type === 'multipleRecordLinks' && f.options && f.options.linkedTableId);
      for (const f of linkFields) {
        const other = tableById(exportSchema, f.options.linkedTableId);
        if (!other) continue;
        const b = slug(other.name);

        const linkFieldSlug = slug(f.name) || 'link';
        const jn = `_m2m_${a}_${b}_${linkFieldSlug}`;
        const rawName = `${jn}__raw`;
        const cols = ['a_airtable_id', 'b_airtable_id'];
        const aCol = `${a}_id`;
        const bCol = (a === b) ? `${b}1_id` : `${b}_id`;

        const jrows = [];
        for (const r of rowsRaw) {
          const aId = r.id || r.airtable_id || r.recordId || null;
          if (!aId) continue;
          const fieldsObj = (r.fields && typeof r.fields === 'object') ? r.fields : r;
          const linked = fieldsObj[f.name];
          if (!linked) continue;
          const linkedIds = Array.isArray(linked) ? linked : [linked];
          for (const bId of linkedIds) {
            if (!bId) continue;
            jrows.push({ a_airtable_id: aId, b_airtable_id: bId });
          }
        }
        if (!jrows.length) continue;

        const csvPath = writeCsv(csvDir, rawName, cols, jrows);
        const relJ = path.relative(POSTGRES_OUT_DIR, csvPath).replace(/\\/g,'/');
        loadSql.push(`\n-- Link field: ${aName}.${f.name} -> ${other.name}\n`);
        loadSql.push(`CREATE TEMP TABLE ${ident(rawName)}(${ident('a_airtable_id')} text, ${ident('b_airtable_id')} text);\n`);
        loadSql.push(`\\copy ${ident(rawName)}(${cols.map(ident).join(',')}) FROM :'basedir'/'${relJ}' WITH (FORMAT csv, HEADER true);\n`);
        loadSql.push(`INSERT INTO ${ident(jn)}(${ident(aCol)}, ${ident(bCol)})\n`);
        loadSql.push(`SELECT a.nocopk, b.nocopk\nFROM ${ident(rawName)} r\nJOIN ${ident(a)} a ON a.airtable_id = r.a_airtable_id\nJOIN ${ident(b)} b ON b.airtable_id = r.b_airtable_id;\n`);
        loadSql.push(`DROP TABLE ${ident(rawName)};\n`);
      }
    }

    loadSql.push('COMMIT;\n');
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '010_load.sql'), loadSql.join(''), 'utf8');
  }

  console.log('[OK] Wrote Postgres artifacts to:', POSTGRES_OUT_DIR);
  console.log(' - 001_tables.sql');
  console.log(' - 002_links.sql');
  console.log(' - 003_views.sql');
  console.log(' - 004_computed_views.sql (from tables_dump.json when present)');
  console.log(' - 010_load.sql + csv/*.csv');
}

main();
