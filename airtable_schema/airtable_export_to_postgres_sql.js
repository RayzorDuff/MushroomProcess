#!/usr/bin/env node
require('./load_env');
/**
 * Script: airtable_export_to_postgres_sql.js
 * Version: 2026-02-03.2
 * =============================================================================
 *  Copyright © 2025 Dank Mushrooms, LLC
 *  Licensed under the GNU General Public License v3 (GPL-3.0-only)
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 3 of the License.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with this program. If not, see <https://www.gnu.org/licenses/>.
 * =============================================================================
 * Direct airtable-export -> Postgres artifacts generator.
 * Goals:
 *  - Create base tables for STORED fields only (no lookup/rollup/formula as physical columns)
 *  - Represent links:
 *      - singleRecordLink: <field>_id BIGINT (references other.nocopk)
 *      - multipleRecordLinks: junction table _m2m_<a>_<b>_<field>(<a>_id, <b>_id) with FKs
 *  - Provide "presentation" views v_<table> that add:
 *      - __table, __primary (best-effort from primaryFieldId)
 *      - link arrays for junction links
 *  - Emit CSV loader script (\copy) when AIRTABLE_EXPORT_DIR is provided (best-effort).
 *
 * Outputs into POSTGRES_OUT_DIR:
 *   001_tables.sql            Base tables with STORED fields only (no lookup/rollup/formula as physical cols)
 *   002_links.sql             Junction tables + FK constraints for multipleRecordLinks
 *   003_views.sql             v_<table> views with __table, __primary (best-effort) and link id arrays
 *   004_computed_views.sql    <-- now compiled from TABLES_DUMP_PATH when present
 *   010_load.sql + csv/*.csv  Relational CSV + loader (base tables + junction resolution via airtable_id)
 *
 * Notes:
 *  - We avoid relying on NocoDB meta APIs entirely.
 *  - multipleRecordLinks are exported into junction tables (CSV) and resolved by airtable_id -> nocopk during load.
 *  - singleRecordLink loading is NOT implemented yet (needs mapping logic similar to junctions); we currently skip.
 *  - rollup aggregation formula is not present in airtable-export output, so rollups are emitted as array_agg with TODO.
 * Usage:
 *   node airtable_export_to_postgres_sql.js
 *
 * Known limitations:
 *   - Airtable rollup aggregation formula is NOT present in the get-tables payload you provided,
 *     so rollups are emitted as array_agg(...) with TODO comments (same limitation as before).
 *   - Formula compiler is "best effort" for common Airtable functions used in this base (IF/AND/OR/NOT,
 *     string concat via &, LEFT/RIGHT/MID, DATETIME_FORMAT, RECORD_ID, CREATED_TIME). Unhandled functions
 *     become NULL and are annotated in SQL comments. 
 *
 * Env:
 *   AIRTABLE_SCHEMA_PATH=./export/_schema.json
 *   TABLES_DUMP_PATH=./export/tables_dump.json
 *   POSTGRES_SCHEMA=public
 *   POSTGRES_OUT_DIR=./pg_out
 *   AIRTABLE_EXPORT_DIR=./export     (optional; directory with per-table JSON exports)
 *   CREATE_VIEWS=true              (default true)
 *   BIGINT_PKS=true                 (default true; creates nocopk BIGSERIAL PK and stores airtable_id)
 */

const fs = require('fs');
const path = require('path');

function envBool(name, defVal) {
  const v = (process.env[name] ?? '').toString().trim();
  if (!v) return defVal;
  return /^true|1|yes|y$/i.test(v);
}

const AIRTABLE_EXPORT_DIR = process.env.AIRTABLE_EXPORT_DIR || '';
const AIRTABLE_SCHEMA_PATH = process.env.AIRTABLE_SCHEMA_PATH ||  path.join(AIRTABLE_EXPORT_DIR, '_schema.json');
const TABLES_DUMP_PATH = process.env.TABLES_DUMP_PATH || (
  AIRTABLE_EXPORT_DIR ? path.join(AIRTABLE_EXPORT_DIR, 'tables_dump.json') : path.join(path.dirname(AIRTABLE_SCHEMA_PATH), 'tables_dump.json')
);
const POSTGRES_SCHEMA = (process.env.POSTGRES_SCHEMA || 'public').toString();
const POSTGRES_OUT_DIR = process.env.POSTGRES_OUT_DIR || './pg_out';
const CREATE_VIEWS = envBool('CREATE_VIEWS', true);
const BIGINT_PKS = envBool('BIGINT_PKS', true);

function die(msg) { console.error('[ERROR]', msg); process.exit(1); }
function readJson(p) { return JSON.parse(fs.readFileSync(p, 'utf8')); }
function ensureDir(p) { fs.mkdirSync(p, { recursive: true }); }
function ident(name) { return '"' + String(name).replace(/"/g, '""') + '"'; }
function literalText(s) { return "'" + String(s).replace(/'/g, "''") + "'"; }
function slug(name) { return String(name).toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, ''); }
function sqlHeader() { return `-- Generated by airtable_export_to_postgres_sql_v3.js\n-- ${new Date().toISOString()}\n`; }


function autogenIdSpec(f, tableName) {
  // Detect Airtable-style ID formulas like:
  //   "LOT-" & DATETIME_FORMAT(CREATED_TIME(),'YYMMDD') & "-" & RIGHT(RECORD_ID(),4)
  if (!f || f.type !== 'formula') return null;
  const fname = String(f.name || '');
  if (!/_id$/i.test(fname)) return null;
  const formula = String((f.options && f.options.formula) || '').trim();
  const m = formula.match(/^"([^"]+)"\s*&\s*DATETIME_FORMAT\(CREATED_TIME\(\),\s*'YYMMDD'\s*\)\s*&\s*"-"\s*&\s*RIGHT\(RECORD_ID\(\),\s*4\s*\)\s*$/i);
  if (!m) return null;
  const prefix = m[1];
  // Only treat as autogen if the prefix looks like an ID prefix (ends with '-')
  if (!/-$/.test(prefix)) return null;
  return { fieldName: fname, prefix };
}

// SQL expression for stable record-id fallback for NocoDB-created rows.
function recordIdFallbackExpr(qualifier) {
  const q = qualifier || '';
  const dot = q ? (q + '.') : '';
  // Prefer legacy id if present (generated elsewhere); otherwise Airtable id; otherwise nocouuid; otherwise nocopk.
  // Note: gen_random_uuid() default is not guaranteed to be visible in BEFORE triggers unless set explicitly there.
  return `COALESCE(NULLIF(${dot}${ident('airtable_id')}::text,''), replace(${dot}${ident('nocouuid')}::text,'-',''), ${dot}${ident('nocopk')}::text)`;
}

function pgTypeForField(f) {
  const t = f.type;
  if (t === 'checkbox') return 'boolean';
  if (t === 'number' || t === 'currency' || t === 'percent' || t === 'rating') return 'numeric';
  if (t === 'count') return 'bigint';
  if (t === 'date') return 'date';
  if (t === 'dateTime' || t === 'createdTime' || t === 'lastModifiedTime') return 'timestamp without time zone';
  if (t === 'duration') return 'numeric';
  if (t === 'phoneNumber' || t === 'email' || t === 'url' || t === 'barcode') return 'text';
  if (t === 'singleSelect' || t === 'multipleSelects') return 'text';
  if (t === 'multilineText' || t === 'richText' || t === 'singleLineText') return 'text';
  if (t === 'attachment' || t === 'multipleAttachments') return 'jsonb';
  if (t === 'multipleRecordLinks') return null;
  if (t === 'singleRecordLink') return 'bigint';
  if (t === 'lookup' || t === 'multipleLookupValues' || t === 'rollup') return null;
  if (t === 'formula') {
    // Store autogen *_id formula fields as real columns so they can be used as NocoDB display values and indexed.
    if (autogenIdSpec(f)) return 'text';
    return null;
  }
  if (t === 'autoNumber') return 'bigint';
  if (t === 'collaborator' || t === 'multipleCollaborators') return 'text';
  if (t === 'button') return null;
  if (t === 'aiText') return 'text';
  return 'text';
}

// Return an empty array literal with the appropriate Postgres array type.
// Using ARRAY[] avoids fragile casts like '{}'::timestamp without time zone[].
function emptyArrayForPgScalar(pgScalar) {
  const t = (pgScalar || 'text').trim();
  return `ARRAY[]::${t}[]`;
}

// Cast an expression to a concrete scalar type when it will be used inside
// array_agg(...). This avoids Postgres polymorphic ambiguity errors like:
//   ERROR: function array_agg(unknown) is not unique
// when the aggregated expression is a bare string literal (type "unknown").
function castForArrayAgg(expr, pgScalar) {
  const t = (pgScalar || 'text').trim();
  // If it's already an explicit cast, leave it.
  const e = String(expr || 'NULL').trim();
  if (/::\s*\w/i.test(e)) return e;
  return `((${e})::${t})`;
}


// Resolve a lookup/rollup target column slug on the linked table.
// Airtable "get tables" payload sometimes returns a target field name that is prefixed
// (e.g. "strain_species_strain") even though the physical column is "species_strain".
// Prefer an exact physical match; otherwise pick the longest physical column name that
// is a suffix of the requested slug.
function resolveLookupTargetSlug(physicalSet, requestedSlug) {
  if (!requestedSlug) return requestedSlug;
  if (physicalSet && physicalSet.has(requestedSlug)) return requestedSlug;
  if (!physicalSet || physicalSet.size === 0) return requestedSlug;
  let best = null;
  for (const col of physicalSet) {
    if (requestedSlug === col) return col;
    if (requestedSlug.endsWith('_' + col) || requestedSlug.endsWith(col)) {
      if (!best || col.length > best.length) best = col;
    }
  }
  return best || requestedSlug;
}


// Junction table naming used in 002_links.sql:
//   _m2m_<a>_<b>_<linkFieldSlug>
function m2mJoinName(aSlug, linkFieldSlug, bSlug) {
  return `_m2m_${aSlug}_${bSlug}_${linkFieldSlug}`;
}

function isComputedType(type) { return ['lookup','multipleLookupValues','rollup','formula'].includes(type); }

function tableById(schema, tid) { return (schema.tables || []).find(t => t.id === tid); }
function findFieldById(table, fid) { return (table.fields || []).find(x => x.id === fid); }

function findTableFile(dir, tableName) {
  const tableSlug = slug(tableName);
  const candidates = [
    path.join(dir, `${tableSlug}.json`),
    path.join(dir, `${tableName}.json`),
    path.join(dir, `${tableName}.records.json`),
  ];
  return candidates.find(p => fs.existsSync(p)) || '';
}

function writeCsv(csvDir, relName, cols, rows) {
  const csvPath = path.join(csvDir, `${relName}.csv`);
  const esc = (v) => {
    if (v === null || v === undefined) return '';
    const s = String(v);
    if (/[",\n\r]/.test(s)) return '"' + s.replace(/"/g,'""') + '"';
    return s;
  };
  const lines = [];
  lines.push(cols.map(esc).join(','));
  for (const r of rows) lines.push(cols.map(c => esc(r[c])).join(','));
  fs.writeFileSync(csvPath, lines.join('\n'), 'utf8');
  return csvPath;
}

// ---------- Airtable formula compiler (best-effort) ----------

function stripWs(s) { return String(s || '').replace(/\r\n/g, '\n').trim(); }

function splitTopLevelArgs(s) {
  // splits "a, b, IF(...), 'x,y'" at commas not inside parens/quotes
  const args = [];
  let cur = '';
  let depth = 0;
  let inS = false, inD = false;
  for (let i=0;i<s.length;i++) {
    const ch = s[i];
    const prev = s[i-1];
    if (ch === "'" && !inD && prev !== '\\') inS = !inS;
    if (ch === '"' && !inS && prev !== '\\') inD = !inD;
    if (!inS && !inD) {
      if (ch === '(') depth++;
      else if (ch === ')') depth = Math.max(0, depth-1);
      else if (ch === ',' && depth === 0) {
        args.push(cur.trim()); cur=''; continue;
      }
    }
    cur += ch;
  }
  if (cur.trim()) args.push(cur.trim());
  return args;
}

function convertStringLiterals(expr) {
  // Airtable uses "double quotes" for strings; Postgres uses single quotes.
  // This is naive but works for your dump where strings are in double quotes.
  // We avoid touching already single-quoted strings.
  let out = '';
  let inS=false, inD=false;
  for (let i=0;i<expr.length;i++) {
    const ch=expr[i];
    const prev=expr[i-1];
    if (ch==="'" && !inD && prev!=="\\") { inS=!inS; out+=ch; continue; }
    if (ch=='"' && !inS && prev!=="\\") { inD=!inD; out += (inD ? "'" : "'"); continue; }
    out+=ch;
  }
  return out;
}

function mapDatetimeFormat(fmt) {
  // Very small mapping for patterns we saw (YYMMDD, YY, MM, DD, etc)
  // Airtable uses moment.js; Postgres uses to_char patterns.
  // We'll handle YYMMDD and a few tokens; otherwise pass through.
  const f = fmt.replace(/^'|'$/g,''); // strip quotes
  const map = {
    'YYMMDD': 'YYMMDD',
    'YY': 'YY',
    'YYYY': 'YYYY',
    'MM': 'MM',
    'DD': 'DD',
    'HH': 'HH24',
    'hh': 'HH12',
    'mm': 'MI',
  };
  return map[f] ? `'${map[f]}'` : `'${f}'`;
}

function compileFormulaExpr(raw, ctx) {
  // ctx: { qualifier: 'base'|'btbl'|'comp', fieldIdToCol: Map(fieldId->colSlug), fieldIdToType?:Map(fieldId->'scalar'|'array') }
  let expr = stripWs(raw);
  if (!expr) return { sql: 'NULL', notes: ['empty formula'] };

  expr = expr.replace(/\s+/g, ' ').trim();
  // Track which column slugs are array-typed for this table. We avoid runtime
  // pg_typeof/unnest/subscript tricks because Postgres type-checks both CASE
  // branches and will error if we attempt array operations on scalar columns.
  // Airtable lookup/rollup fields are arrays; everything else is treated as scalar.
  const __arrayCols = new Set();
  if (ctx && ctx.fieldById && ctx.fieldIdToCol) {
    for (const [fid, f] of ctx.fieldById.entries()) {
      const col = ctx.fieldIdToCol.get(fid);
      if (!col || !f) continue;
      if (f.type === 'multipleLookupValues' || f.type === 'rollup') __arrayCols.add(col);
    }
  }

  function compileSingleLinkDisplay(linkField, ctx) {
    // When a formula references a single-record link field, Airtable returns the linked record's primary field display.
    // We emulate that by selecting the linked table's primary field (best-effort) for the first linked row.
    try {
      const opts = linkField.options || {};
      if (!opts.linkedTableId) return "''";
      const thisSlug = slug(ctx.tableObj.name);
      const linkSlug = slug(linkField.name);
      const other = tablesDump ? tableById(tablesDump, opts.linkedTableId) : null;
      const otherExport = exportTableById.get(opts.linkedTableId) || null;
      const otherSlug = slug((other && other.name) || (otherExport && otherExport.name) || '');
      if (!otherSlug) return "''";
  
      const joinTable = m2mJoinName(thisSlug, linkSlug, otherSlug);
      const leftFk = `${thisSlug}_id`;
      const rightFk = (thisSlug === otherSlug) ? `${otherSlug}1_id` : `${otherSlug}_id`;
  
      // Determine the linked table's primary field
      let primaryField = null;
      if (other && other.primaryFieldId) primaryField = findFieldById(other, other.primaryFieldId);
      if (!primaryField && otherExport && otherExport.primaryFieldId) {
        const m = tableFieldById.get(otherExport.id);
        if (m) primaryField = m.get(otherExport.primaryFieldId);
      }
  
      let displayExpr = "btbl." + ident("airtable_id");
      if (primaryField) {
        if (primaryField.type === 'formula' && primaryField.options && primaryField.options.formula) {
          displayExpr = compileFormulaFor(other || otherExport || ctx.tableObj, primaryField, 'btbl');
        } else {
          displayExpr = "btbl." + ident(slug(primaryField.name));
        }
      }
  
      const otherRel = (thisSlug === otherSlug)
        ? `${ident(POSTGRES_SCHEMA)}.${ident('v_' + thisSlug)}`
        : `${ident(POSTGRES_SCHEMA)}.${ident('v_' + otherSlug)}`;
  
      return `COALESCE((SELECT (${displayExpr})::text FROM ${ident(POSTGRES_SCHEMA)}.${ident(joinTable)} j ` +
             `JOIN ${otherRel} btbl ON btbl.${ident('nocopk')} = j.${ident(rightFk)} ` +
             `WHERE j.${ident(leftFk)} = ${ctx.qualifier}.${ident('nocopk')} ` +
             `ORDER BY btbl.${ident('nocopk')} LIMIT 1), '')`;
    } catch (e) {
      return "''";
    }
  }

    // Convert Airtable "double quoted" strings to SQL single quotes (best-effort)
  // Do this BEFORE field replacement so we don't turn SQL identifiers ("col") into string literals ('col').
  expr = convertStringLiterals(expr);

  // Replace Airtable field references {fld...} with qualified identifiers.
  expr = expr.replace(/\{(fld[A-Za-z0-9]+)\}/g, (_m, fid) => {
    const f = ctx.fieldById && ctx.fieldById.get(fid);

    // Single-record link display behavior
    if (f && f.type === 'multipleRecordLinks' && f.options && f.options.prefersSingleRecordLink) {
      return compileSingleLinkDisplay(f, ctx);
    }

    // If a formula references another formula field in the SAME table, we cannot safely
    // emit comp."col" because that column does not exist in the comp CTE (it is computed
    // later in the SELECT list). Instead, inline the referenced formula.
    if (f && f.type === 'formula' && typeof ctx.compileFormulaFor === 'function') {
      // Prevent direct self-recursion
      if (ctx.currentFieldId && f.id === ctx.currentFieldId) return 'NULL';
      return `(${ctx.compileFormulaFor(ctx.tableObj, f, ctx.qualifier, ctx._formulaStack || [])})`;
    }

    const col = ctx.fieldIdToCol.get(fid);
    if (!col) return 'NULL';

    // If formulas reference the imported Airtable record id column directly (airtable_id),
    // new rows created in NocoDB will have it NULL. In Airtable, this pattern is usually
    // intended to behave like RECORD_ID(). So we fall back to nocouuid/nocopk (and legacy id if present).
    if (col === 'airtable_id') {
      if (ctx && ctx.hasLegacy && ctx.legacySlug) {
        return `COALESCE(NULLIF(${ctx.qualifier}.${ident(ctx.legacySlug)}::text,''), NULLIF(${ctx.qualifier}.${ident('airtable_id')}::text,''), replace(${ctx.qualifier}.${ident('nocouuid')}::text,'-',''), (${ctx.qualifier}.${ident('nocopk')})::text)`;
      }
      return `COALESCE(NULLIF(${ctx.qualifier}.${ident('airtable_id')}::text,''), replace(${ctx.qualifier}.${ident('nocouuid')}::text,'-',''), (${ctx.qualifier}.${ident('nocopk')})::text)`;
    }

    return `${ctx.qualifier}.${ident(col)}`;
  });

  // Normalize TRUE()/FALSE()/BLANK()
  expr = expr.replace(/\bTRUE\s*\(\s*\)/gi, 'TRUE');
  expr = expr.replace(/\bFALSE\s*\(\s*\)/gi, 'FALSE');
  expr = expr.replace(/\bBLANK\s*\(\s*\)/gi, "''");

  // Replace & (string concat) with ||
  {
    let out = '';
    let inS=false;
    for (let i=0;i<expr.length;i++) {
      const ch=expr[i];
      if (ch==="'" && expr[i-1]!=="\\") inS=!inS;
      if (!inS && ch==='&') out += '||';
      else out += ch;
    }
    expr = out;
  }

  const notes = [];
  const AIRTABLE_FUNCS = new Set(['IF', 'AND', 'OR', 'NOT', 'LOWER', 'UPPER', 'LEN', 'LEFT', 'RIGHT', 'MID', 'ROUND', 'VALUE', 'SUM', 'CONCAT', 'CONCATENATE', 'YEAR', 'MONTH', 'DAY', 'ISBLANK', 'ISNOTBLANK', 'DATETIME_FORMAT', 'CREATED_TIME', 'LAST_MODIFIED_TIME', 'RECORD_ID', 'SET_TIMEZONE', 'DATEADD', 'REGEX_REPLACE', 'ARRAYSLICE', 'ARRAYSPLICE', 'ARRAYJOIN', 'SWITCH']);

  
  function squashRedundantCasts(expr) {
    let e = expr;
    // iteratively squash repeated casts: (x::text)::text -> x::text
    const rules = [
      ['text','text'],
      ['numeric','numeric'],
      ['int','int'],
      ['timestamp','timestamp'],
      ['date','date'],
      ['boolean','boolean'],
    ];
    for (let pass=0; pass<50; pass++) {
      let changed = false;
      for (const [t1,t2] of rules) {
        const re = new RegExp(`\\)\s*::\s*${t1}\s*\\)\s*::\s*${t2}`, 'gi');
        const next = e.replace(re, `)::${t1}`);
        if (next !== e) { e = next; changed = true; }
      }
      if (!changed) break;
    }
    return e;
  }

  function truthy(x) {
    const s = x.trim();
    // Airtable treats blank/empty as false for IF conditions.
    // If condition is a bare field reference, compile to ISNOTBLANK style.
    // For lookup/rollup arrays, treat empty array as blank (cardinality = 0).
    const m = /^(base|btbl|comp)\."([^"]+)"$/.exec(s);
    if (m) {
      const col = m[2];
      if (__arrayCols && __arrayCols.has(col)) return `COALESCE(cardinality(${s}),0) > 0`;
      return `NULLIF(${s}::text,'') IS NOT NULL`;
    }
    return s;
  }

  function mapDatetimeFormat(fmt) {
    const f = fmt.replace(/^'|'$/g,'');
    const map = { 'YYMMDD':'YYMMDD','YY':'YY','YYYY':'YYYY','MM':'MM','DD':'DD','HH':'HH24','hh':'HH12','mm':'MI' };
    return map[f] ? `'${map[f]}'` : `'${f}'`;
  }

  function splitArgs(inner) { return splitTopLevelArgs(inner); }

  // Cast helper used by the formula compiler. Airtable lookups/rollups are arrays,
  // but many formulas treat them as scalars (e.g., to_char({spawned_date}, ...)).
  // We only scalarize *when we know the referenced column is an array* to avoid
  // generating SQL like `comp."airtable_id"[1]` (which Postgres rejects at parse-time).
  function ensureCast(expr, castType) {
    let s = String(expr).trim();
    const ct = String(castType).trim();

    // If we are casting to a scalar type and the expression is a simple qualified
    // column reference to a known array-typed column, take the first element.
    if (!/\[\]\s*$/.test(ct)) {
      const m = s.match(/^(base|btbl|comp)\."([^"]+)"$/);
      if (m && __arrayCols.has(m[2])) {
        s = `(${s})[1]`;
      }
  
    }

    // If we are casting to an array type but the expression is scalar (common when
    // comparing lookup/rollup arrays to scalar literals), wrap it as a 1-element array.
    if (/\[\]\s*$/.test(ct)) {
      if (!isArrayExpr(s)) {
        const baseType = ct.replace(/\[\]\s*$/, '').trim();
        // Cast inner value to base type to avoid polymorphic/unknown literal issues.
        s = `ARRAY[(${s})::${baseType}]`;
      }
    }


    const re = new RegExp(`::\\s*${ct}\\s*$`, 'i');
    if (re.test(s)) return s;
    return `(${s})::${ct}`;
  }
  

  function isSimpleArrayColRef(expr) {
    const s = String(expr || '').trim();
    const m = s.match(/^(base|btbl|comp)\."([^"]+)"$/);
    if (!m) return false;
    return __arrayCols.has(m[2]);
  }

  function isArrayExpr(expr) {
    const s = String(expr || '').trim();
    if (/::\s*\w+\s*\[\]\s*$/i.test(s)) return true;
    if (/\bARRAY\s*\[/i.test(s)) return true;
    if (/\barray_agg\s*\(/i.test(s)) return true;
    if (isSimpleArrayColRef(s)) return true;
    return false;
  }

  function scalarizeArrayExprToText(expr) {
    // Best-effort: if it's a direct reference to an array-typed column, take first element.
    const s = String(expr || '').trim();
    if (isSimpleArrayColRef(s)) return ensureCast(s, 'text');
    return s;
  }  

  // When Airtable formulas concatenate text using `&` (compiled here as `||`),
  // Airtable coerces lookup/rollup arrays to a string. Postgres does not.
  // If we leave an array-typed lookup/rollup reference uncoerced, expressions like
  // `'' || comp."some_lookup" || ' '` can trigger "malformed array literal" errors
  // because Postgres tries to interpret adjacent string literals as array literals.
  //
  // We fix this by scalarizing known array-typed column refs *only when* they're
  // used adjacent to the concatenation operator.
  function coerceArrayRefsInConcat(sqlExpr) {
    const s = String(sqlExpr);
    let out = '';
    let i = 0;
    let inS = false;
    while (i < s.length) {
      const ch = s[i];
      if (ch === "'" && s[i - 1] !== "\\") {
        inS = !inS;
        out += ch;
        i++;
        continue;
      }
      if (!inS) {
        const m = s.slice(i).match(/^(base|btbl|comp)\."([^"]+)"/);
        if (m) {
          const full = m[0];
          const qual = m[1];
          const col = m[2];

          // Detect if this ref is adjacent to `||` on either side (ignoring whitespace)
          let leftIsConcat = false;
          {
            let j = out.length - 1;
            while (j >= 0 && /\s/.test(out[j])) j--;
            if (j >= 1 && out[j] === '|' && out[j - 1] === '|') leftIsConcat = true;
          }
          let rightIsConcat = false;
          {
            let j = i + full.length;
            while (j < s.length && /\s/.test(s[j])) j++;
            if (j + 1 < s.length && s[j] === '|' && s[j + 1] === '|') rightIsConcat = true;
          }

          if ((leftIsConcat || rightIsConcat) && __arrayCols.has(col)) {
            // Coerce to scalar text; Airtable-ish behavior is "first element".
            out += `COALESCE(((${qual}."${col}")[1])::text, '')`;
            i += full.length;
            continue;
          }

          out += full;
          i += full.length;
          continue;
        }
      }
      out += ch;
      i++;
    }
    return out;
  }

  // Compile a single function call NAME(args...) where args are already compiled SQL expressions.
  function compileFunc(name, args) {
    const fn = name.toUpperCase();

    if (fn === 'IF' && (args.length === 2 || args.length === 3)) {
      const cond=args[0];
      let tVal=args[1];
      let fVal=(args.length===3?args[2]:'NULL');

      // Airtable often mixes computed arrays (lookup/rollup) with scalar text in IF().
      // Postgres requires CASE branches to resolve to a single type. If we detect a
      // simple array-typed column ref on one side and a scalar on the other, coerce
      // the array ref to scalar text (first element) to match Airtable-ish behavior.
      const tIsArr = isArrayExpr(tVal);
      const fIsArr = isArrayExpr(fVal);
      if (tIsArr !== fIsArr) {
        if (tIsArr) tVal = scalarizeArrayExprToText(tVal);
        if (fIsArr) fVal = scalarizeArrayExprToText(fVal);
      }

      return `CASE WHEN (${truthy(cond)}) THEN (${tVal}) ELSE (${fVal}) END`;
    }
    if (fn === 'AND') return '(' + args.map(a=>`(${a})`).join(' AND ') + ')';
    if (fn === 'OR') return '(' + args.map(a=>`(${a})`).join(' OR ') + ')';
    if (fn === 'NOT' && args.length===1) return `(NOT (${args[0]}))`;

    if (fn === 'LOWER' && args.length >= 1) return `"lower"(${ensureCast(args[0], 'text')})`;
    if (fn === 'UPPER' && args.length===1) return `"upper"(${ensureCast(args[0],'text')})`;
    if (fn === 'LEN' && args.length===1) return `"length"(${ensureCast(args[0],'text')})`;

    if (fn === 'LEFT' && args.length >= 2) return `"left"(${ensureCast(args[0], 'text')}, ${ensureCast(args[1], 'int')})`;
    if (fn === 'RIGHT' && args.length >= 2) return `"right"(${ensureCast(args[0], 'text')}, ${ensureCast(args[1], 'int')})`;
    if (fn === 'MID' && args.length===3) return `SUBSTRING(${ensureCast(args[0], 'text')} FROM ${ensureCast(args[1],'int')} FOR ${ensureCast(args[2],'int')})`;

    if (fn === 'ROUND' && (args.length===1 || args.length===2)) {
      const d = args.length===2 ? args[1] : '0';
      return `"round"(${ensureCast(args[0],'numeric')}, ${ensureCast(d,'int')})`;
    }

    if (fn === 'VALUE' && args.length===1) return ensureCast(`NULLIF((${args[0]})::text,'')`, 'numeric');
    if (fn === 'SUM') return '(' + args.map(a=>`COALESCE(${ensureCast(a,'numeric')},0)`).join(' + ') + ')';
    if (fn === 'CONCAT' || fn === 'CONCATENATE') {
      // If single arg looks like array, turn into array_to_string; otherwise concat as text.
      if (args.length===1) return `array_to_string((${args[0]})::text[], '')`;
      return '(' + args.map(a=>`(${a})::text`).join('||') + ')';
    }

    if (fn === 'YEAR' && args.length===1) return `EXTRACT(YEAR FROM ${ensureCast(args[0], 'timestamp')})`;
    if (fn === 'MONTH' && args.length===1) return `EXTRACT(MONTH FROM ${ensureCast(args[0], 'timestamp')})`;
    if (fn === 'DAY' && args.length===1) return `EXTRACT(DAY FROM ${ensureCast(args[0], 'timestamp')})`;

    if (fn === 'ISBLANK' && args.length===1) return `((NULLIF((${args[0]})::text,'') IS NULL))`;
    if (fn === 'ISNOTBLANK' && args.length===1) return `((NULLIF((${args[0]})::text,'') IS NOT NULL))`;

    if (fn === 'DATETIME_FORMAT') {
      const dtArg = args[0];
      const fmtArg = (args.length>=2 ? args[1] : `'YYYY-MM-DD'`);

      const fmt = mapDatetimeFormat(fmtArg);
      return `to_char(${ensureCast(dtArg, 'timestamp')}, ${fmt})`;
    }
    if (fn === 'CREATED_TIME' && args.length===0) return `${ctx.qualifier}.${ident('nc_created_at')}`;
    if (fn === 'LAST_MODIFIED_TIME' && args.length===0) return `${ctx.qualifier}.${ident('nc_updated_at')}`;
    if (fn === 'RECORD_ID' && args.length===0) {
      // Airtable RECORD_ID() is always available in Airtable but not in Postgres.
      // For imported rows, we want to preserve the Airtable record id (airtable_id or legacy id if you have one).
      // For newly-created rows in NocoDB, airtable_id will be NULL, so we fall back to nocouuid (stable) and then nocopk.
      if (ctx && ctx.hasLegacy) {
        return `COALESCE(NULLIF(${ctx.qualifier}.${ident(ctx.legacySlug)}::text,''), NULLIF(${ctx.qualifier}.${ident('airtable_id')}::text,''), replace(${ctx.qualifier}.${ident('nocouuid')}::text,'-',''), (${ctx.qualifier}.${ident('nocopk')})::text)`;
      }
      return `COALESCE(NULLIF(${ctx.qualifier}.${ident('airtable_id')}::text,''), replace(${ctx.qualifier}.${ident('nocouuid')}::text,'-',''), (${ctx.qualifier}.${ident('nocopk')})::text)`;
    }

    if (fn === 'SET_TIMEZONE' && args.length===2) return `(${args[0]})`;
    if (fn === 'DATEADD' && args.length===3) {
      // DATEADD(datetime, n, 'days') style (Airtable)
      const unit = (args[2]||'').replace(/^'|'$/g,'').toLowerCase();
      const unitMap = { years:'year', year:'year', months:'month', month:'month', days:'day', day:'day', hours:'hour', hour:'hour', minutes:'minute', minute:'minute', seconds:'second', second:'second' };
      const u = unitMap[unit] || unit;
      return `((${args[0]})::timestamp + (${ensureCast(args[1],'numeric')} * (INTERVAL '1 ' || ${literalText(''+u)})))`;
    }

    if (fn === 'REGEX_REPLACE' && (args.length===3 || args.length===4)) {
      // regexp_replace(str, pattern, replacement, 'g')
      const flags = args.length===4 ? args[3] : `'g'`;
      return `regexp_replace((${args[0]})::text, (${args[1]})::text, (${args[2]})::text, (${flags})::text)`;
    }

    if ((fn === 'ARRAYSLICE' || fn === 'ARRAYSLICE') && args.length>=3) {
      // Airtable ARRAYSPLICE(arr, start, count) start is 0-based
      const arr = args[0];
      const start = args[1];
      const count = args[2];
      // Convert to 1-based slice: [start+1 : start+count]
      return `(${arr})::text[][((${start})::int + 1): ((${start})::int + (${count})::int)]`;
    }

    if (fn === 'ARRAYJOIN' && (args.length===1 || args.length===2)) {
      const delim = args.length===2 ? args[1] : `''`;
      return `array_to_string((${args[0]})::text[], (${delim})::text)`;
    }

    if ((fn === 'ARRAYSLICE' || fn === 'ARRAYSPLICE') && args.length >= 3) {
      // Airtable ARRAYSPLICE/ARRAYSLICE(arr, start, count) with 0-based start.
      const arr = args[0];
      const start = args[1];
      const count = args[2];
      return `(${arr})::text[][((${start})::int + 1) : ((${start})::int + (${count})::int)]`;
    }


    if (fn === 'SWITCH' && args.length>=3) {
      // SWITCH(expr, val1, res1, val2, res2, ..., default?)
      const switchExpr = args[0];
      const pairs = args.slice(1);
      const hasDefault = (pairs.length % 2) === 1;
      let defaultExpr = hasDefault ? pairs[pairs.length-1] : "''";
      const lim = hasDefault ? pairs.length-1 : pairs.length;

      // Similar to IF(): if any result branch is an array-typed column and others are scalar,
      // scalarize array column refs to text to keep CASE type resolution valid.
      const resultExprs = [];
      for (let i=0;i<lim;i+=2) resultExprs.push(pairs[i+1]);
      resultExprs.push(defaultExpr);

      const anyArr = resultExprs.some(isArrayExpr);
      const anyScalar = resultExprs.some(e => !isArrayExpr(e));
      const mixed = anyArr && anyScalar;

      let out = `CASE`;
      for (let i=0;i<lim;i+=2) {
        let res = pairs[i+1];
        if (mixed && isArrayExpr(res)) res = scalarizeArrayExprToText(res);
        out += ` WHEN (${switchExpr}) = (${pairs[i]}) THEN (${res})`;
      }
      if (mixed && isArrayExpr(defaultExpr)) defaultExpr = scalarizeArrayExprToText(defaultExpr);
      out += ` ELSE (${defaultExpr}) END`;
      return out;
    }

    // Unknown function: keep as-is so caller can decide to null it out
    notes.push(`unsupported function ${name}`);
    return `${name}(` + args.join(',') + `)`;
  }

  // Replace innermost function calls iteratively.
  // We scan for NAME(...) patterns and resolve the one with the deepest nesting first.
    const KNOWN_AIRTABLE_FNS = new Set([
    'IF','AND','OR','NOT',
    'LOWER','UPPER','LEN','LEFT','RIGHT','MID','ROUND','VALUE','SUM','CONCAT','CONCATENATE',
    'YEAR','MONTH','DAY',
    'ISBLANK','ISNOTBLANK','BLANK',
    'DATETIME_FORMAT','CREATED_TIME','LAST_MODIFIED_TIME','RECORD_ID',
    'SET_TIMEZONE','DATEADD',
    'REGEX_REPLACE','ARRAYSLICE','ARRAYJOIN',
    'SWITCH'
  ]);

  function compileAllFunctions(e) {
    let s = e;
    // Safety iteration cap
    for (let iter=0; iter<500; iter++) {
      // find an innermost function call: NAME( ... ) with no other '(' inside its arg list.
      // We'll do a manual scan to locate parentheses and match back to function name.
      let best = null; // {start,end,name,inner}
      let inS=false;
      const stack = [];
      for (let i=0;i<s.length;i++) {
        const ch = s[i];
        if (ch==="'" && s[i-1]!=="\\") inS=!inS;
        if (inS) continue;
        if (ch==='(') stack.push(i);
        else if (ch===')' && stack.length) {
          const l = stack.pop();
          // Determine token before '('
          const before = s.slice(0,l).match(/([A-Za-z_][A-Za-z0-9_]*)\s*$/);
          if (!before) continue;
          const name = before[1];
          if (!AIRTABLE_FUNCS.has(name.toUpperCase())) continue;
          const nameStart = l - before[0].length;
          const inner = s.slice(l+1, i);
          // Ensure inner has no unmatched parens (it is innermost by stack mechanics)
          best = { start: nameStart, lparen: l, rparen: i, name, inner };
          break; // this is the first innermost closing we encounter scanning left->right
        }
      }
      if (!best) break;

      const upName = String(best.name || '').toUpperCase();
      // Only compile Airtable functions; leave SQL functions (to_char, regexp_replace, etc.) untouched.
      if (!KNOWN_AIRTABLE_FNS.has(upName)) {
        // Mark this function call as "protected" by skipping it. We break out of this iteration
        // by replacing the '(' with a sentinel so we don't re-detect it.
        s = s.slice(0, best.lparen) + '?' + s.slice(best.lparen + 1);
        continue;
      }

      const rawArgs = splitArgs(best.inner);
      const compiledArgs = rawArgs.map(a => compileAllFunctions(a.trim()));
      const repl = compileFunc(best.name, compiledArgs);
      s = s.slice(0, best.start) + repl + s.slice(best.rparen+1);
    }
    // Restore protected function markers
    s = s.replaceAll('?', '(');

    // Defensive fix: if an OR()/AND() compilation bug ever produced boolean "juxtaposition" like `(a) ((b))`,
    // patch it into `(a) OR ((b))` so Postgres can parse it.
    // This should be a no-op when the compiler is behaving.
    s = s.replace(/\)\s+\(\(/g, ') OR ((');

    return s;
  }


  // Rewrite comparisons between array-typed lookup/rollup columns (text[]) and scalar literals.
  // Airtable allows comparisons like {LookupArray} = 'x' and treats it like "array contains x".
  // In Postgres, (text[] = unknown) can coerce the literal to text[] and fail with malformed array literal.
  function rewriteArrayScalarComparisons(sql) {
    if (!sql) return sql;
    const arrCols = __arrayCols;

    // qual."col" (=|<>|!=) 'literal'
    sql = sql.replace(/([a-zA-Z_][a-zA-Z0-9_]*)\.\"([^\"]+)\"\s*(=|<>|!=)\s*'([^']*)'/g,
      (m, qual, col, op, lit) => {
        if (!arrCols || !arrCols.has(col)) return m;
        const scalar = `('${lit.replace(/'/g, "''")}')::text`;
        const arr = `(${qual}.\"${col}\")::text[]`;
        const any = `${scalar} = ANY(${arr})`;
        return op === '=' ? `(${any})` : `(NOT (${any}))`;
      });

    // 'literal' (=|<>|!=) qual."col"
    sql = sql.replace(/'([^']*)'\s*(=|<>|!=)\s*([a-zA-Z_][a-zA-Z0-9_]*)\.\"([^\"]+)\"/g,
      (m, lit, op, qual, col) => {
        if (!arrCols || !arrCols.has(col)) return m;
        const scalar = `('${lit.replace(/'/g, "''")}')::text`;
        const arr = `(${qual}.\"${col}\")::text[]`;
        const any = `${scalar} = ANY(${arr})`;
        return op === '=' ? `(${any})` : `(NOT (${any}))`;
      });

    return sql;
  }

  let compiled = compileAllFunctions(expr);

  // Only null out when we actually encountered an unsupported Airtable function.
  // The compiled SQL legitimately contains function calls like to_char(), regexp_replace(), left(), right(), etc.
  if (notes && notes.length) {
    return { sql: 'NULL', notes };
  }
  compiled = squashRedundantCasts(compiled);
  // After all Airtable function expansion, coerce known array-typed column refs
  // in string-concatenation contexts to scalar text to avoid Postgres array
  // literal parsing errors.
  compiled = coerceArrayRefsInConcat(compiled);
  compiled = rewriteArrayScalarComparisons(compiled);
  return { sql: compiled, notes: [] };
}


// ---------- Main generator ----------

function main() {
  if (!fs.existsSync(AIRTABLE_SCHEMA_PATH)) die(`Missing AIRTABLE_SCHEMA_PATH: ${AIRTABLE_SCHEMA_PATH}`);
  const exportSchema = readJson(AIRTABLE_SCHEMA_PATH);
  const exportTables = exportSchema.tables || [];
  if (!exportTables.length) die('export/_schema.json has no tables');

  let tablesDump = null;
  // Best-effort: load tables_dump.json (Airtable "get tables" export) if present.
  // This is the authoritative source for lookup/rollup targets (handles manual renames).
  const candidateDumpPaths = [
    TABLES_DUMP_PATH,
    path.join(process.cwd(), 'export', 'tables_dump.json'),
    path.join(process.cwd(), 'tables_dump.json'),
  ].filter(Boolean);

  const foundDumpPath = candidateDumpPaths.find(p => {
    try { return p && fs.existsSync(p); } catch { return false; }
  });

  if (foundDumpPath) {
    tablesDump = readJson(foundDumpPath);
    if (!tablesDump.tables || !Array.isArray(tablesDump.tables)) tablesDump = null;
    console.log('[OK] Read tables from:', TABLES_DUMP_PATH);
  } else {
    console.log('[WARN] Could not read tables from:', TABLES_DUMP_PATH);
  }

  // Use tablesDump for computed + primary if available; otherwise fall back to export schema
  const schema = tablesDump || exportSchema;
  const tables = schema.tables || [];

  ensureDir(POSTGRES_OUT_DIR);

  // FieldId maps and fieldName->id maps
  const tableFieldById = new Map(); // tableId -> Map(fieldId -> field)
  const tableFieldIdToCol = new Map(); // tableSlug -> Map(fieldId -> colSlug)
  const physicalColsByTableSlug = new Map();

  for (const t of tables) {
    const m = new Map();
    const m2 = new Map();
    for (const f of (t.fields || [])) {
      m.set(f.id, f);
      m2.set(f.id, slug(f.name));
    }
    tableFieldById.set(t.id, m);
    tableFieldIdToCol.set(slug(t.name), m2);
  }

  // Junctions: {jn, a, b, aCol, bCol, linkFieldSlug, linkFieldId}
  const junctions = [];

  // 001_tables.sql uses export schema (stored fields are same)
  let ddl = sqlHeader();
  ddl = `-- Requires extension pgcrypto for gen_random_uuid()\nCREATE EXTENSION IF NOT EXISTS pgcrypto;\n\n` + ddl;
  ddl += `BEGIN;\nCREATE SCHEMA IF NOT EXISTS ${ident(POSTGRES_SCHEMA)};\n`;

  for (const t of exportTables) {
    const tn = slug(t.name);
    const cols = [];
    const physical = new Set();
    const colTypeByName = new Map(); // for constraints/indexing decisions
    
    // Always keep internal PK first
    if (BIGINT_PKS) { cols.push(`${ident('nocopk')} BIGSERIAL PRIMARY KEY`); physical.add('nocopk'); colTypeByName.set('nocopk','bigint'); }
    else { cols.push(`${ident('airtable_id')} text PRIMARY KEY`); physical.add('airtable_id'); colTypeByName.set('airtable_id','text'); }
    


    // Materialize Airtable-style autogen ID formula fields (e.g., lot_id, product_id) as real columns.
    // These are computed by triggers later in this file.
    const autogenSpecs = [];
    for (const f of (t.fields || [])) {
      const spec = autogenIdSpec(f, t.name);
      if (spec) autogenSpecs.push(spec);
    }
    for (const s of autogenSpecs) {
      const colName = slug(s.fieldName);
      // Avoid internal/reserved duplicates
      if (colName === 'nocopk' || colName === 'nocouuid' || colName === 'airtable_id' || colName === 'nc_created_at' || colName === 'nc_updated_at') continue;
      if (physical.has(colName)) continue;
      cols.push(`${ident(colName)} text`);
      physical.add(colName);
      colTypeByName.set(colName, 'text');
    }
    // We'll append internal bookkeeping columns at the END so NocoDB is less likely to choose them as "display"/PV.
    const internalCols = [
      { name: 'nocouuid', def: `${ident('nocouuid')} uuid DEFAULT gen_random_uuid()`, typ: 'uuid' },
      { name: 'airtable_id', def: `${ident('airtable_id')} text UNIQUE`, typ: 'text' },
      { name: 'nc_created_at', def: `${ident('nc_created_at')} timestamp without time zone DEFAULT now()`, typ: 'timestamp' },
      { name: 'nc_updated_at', def: `${ident('nc_updated_at')} timestamp without time zone DEFAULT now()`, typ: 'timestamp' },
    ];
        const reserved = new Set(['nocopk','nocouuid','airtable_id','nc_created_at','nc_updated_at']);

    // Determine the first "Airtable" physical field (stored, non-link-array, non-button)
    let firstAirtableCol = null;
    
    // Build a list of Airtable physical columns (excluding reserved/internal),
    // and we'll order them so the first Airtable field follows nocopk.
    const airtableColDefs = [];
    for (const f of (t.fields || [])) {
      if (isComputedType(f.type)) continue;
      if (f.type === 'button') continue;

      const baseName = slug(f.name);
      if (!baseName || reserved.has(baseName)) continue;

      if (f.type === 'singleRecordLink') {
      const colName = (baseName.endsWith('_id') ? baseName : (baseName + '_id'));
      const def = `${ident(colName)} bigint`;
      airtableColDefs.push({ name: colName, def, typ: 'bigint', kind: 'fk' });
      if (!firstAirtableCol) firstAirtableCol = colName;
          continue;
      }

      if (f.type === 'multipleRecordLinks') {
        // Many Airtable link fields are configured as "multipleRecordLinks" even when used as 1:1.
        // If the schema marks the field as preferring single links, materialize a FK column (<field>_id)
        // while still keeping the _m2m_* junction for compatibility.
        if (f.options && f.options.prefersSingleRecordLink) {
          const colName = (baseName.endsWith('_id') ? baseName : (baseName + '_id'));
          const def = `${ident(colName)} bigint`;
          airtableColDefs.push({ name: colName, def, typ: 'bigint', kind: 'fk' });
          if (!firstAirtableCol) firstAirtableCol = colName;
        }
        continue;
      }

      const typ = pgTypeForField(f) || 'text';
      const def = `${ident(baseName)} ${typ}`;
      airtableColDefs.push({ name: baseName, def, typ, kind: 'field' });
      if (!firstAirtableCol) firstAirtableCol = baseName;
    }
    
    // Emit Airtable columns in order:
    //  - first Airtable field immediately after nocopk (for NocoDB display heuristics)
    //  - then remaining Airtable fields
    if (firstAirtableCol) {
      const first = airtableColDefs.find(x => x.name === firstAirtableCol);
      if (first) {
        cols.push(first.def); physical.add(first.name); colTypeByName.set(first.name, first.typ);
      }
      for (const c of airtableColDefs) {
        if (c.name === firstAirtableCol) continue;
        cols.push(c.def); physical.add(c.name); colTypeByName.set(c.name, c.typ);
      }
    } else {
      for (const c of airtableColDefs) {
        cols.push(c.def); physical.add(c.name); colTypeByName.set(c.name, c.typ);
      }
    }

    // Append internal columns LAST
    for (const ic of internalCols) {
      // note: airtable_id is already created as PK when BIGINT_PKS is false; avoid duplicates
      if (physical.has(ic.name)) continue;
      cols.push(ic.def); physical.add(ic.name); colTypeByName.set(ic.name, ic.typ);
    }

    physicalColsByTableSlug.set(tn, physical);

    ddl += `
CREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(tn)} (
  ${cols.join(',\n  ')}
);
`;

    // Constraints / indexes to support display and lookups in NocoDB.
    // - Any TEXT column ending with _id gets UNIQUE + implicit index (Airtable-style identifiers).
    // - The first Airtable physical field gets special handling:
    //     * if it's *_id (text), ensure unique
    //     * if it's name (text), create a non-unique index
  {
    const emittedUniques = new Set();
    const addUnique = (colName) => {
      const cname = `uq_${tn}_${colName}`;
      if (emittedUniques.has(cname)) return;
      emittedUniques.add(cname);

      // Use regclass *literal* (not "schema"."table"::regclass) and interpolate cname safely.
      const rel = `${POSTGRES_SCHEMA}.${tn}`;
      const cnameSql = cname.replace(/'/g, "''");

      ddl += `DO $$ BEGIN
        IF NOT EXISTS (
          SELECT 1
          FROM pg_constraint c
          WHERE c.conname = '${cnameSql}'
            AND c.conrelid = '${rel}'::regclass
        ) THEN
          ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(tn)}
            ADD CONSTRAINT ${ident(cname)} UNIQUE (${ident(colName)});
        END IF;
      END $$;
`;
    };

    const addIndex = (colName) => {
    const iname = `ix_${tn}_${colName}`;
    ddl += `CREATE INDEX IF NOT EXISTS ${ident(iname)} ON ${ident(POSTGRES_SCHEMA)}.${ident(tn)}(${ident(colName)});
`;
  };

    // First airtable column preference
    if (firstAirtableCol) {
      const t0 = colTypeByName.get(firstAirtableCol);
      if (t0 === 'text' && /_id$/.test(firstAirtableCol)) addUnique(firstAirtableCol);
      else if (t0 === 'text' && firstAirtableCol === 'name') addIndex(firstAirtableCol);
    }

    for (const [colName, colTyp] of colTypeByName.entries()) {
      if (colName === 'nocopk' || colName === 'airtable_id') continue;
      if (colTyp !== 'text') continue;
      if (!/_id$/.test(colName)) continue;
      // skip the internal airtable_id column (already unique)
      if (colName === 'airtable_id') continue;
      addUnique(colName);
    }
  }
}

// Create triggers to compute autogen *_id fields (Airtable formula IDs) on insert/update.
// This makes IDs available on base tables (writable) and keeps vc_ views simpler.
for (const t of exportTables) {
  const tn = slug(t.name);
  const specs = [];
  for (const f of (t.fields || [])) {
    const spec = autogenIdSpec(f, t.name);
    if (spec) specs.push(spec);
  }
  if (!specs.length) continue;

  const fnName = `set_autogen_ids_${tn}`;
  ddl += `\nCREATE OR REPLACE FUNCTION ${ident(POSTGRES_SCHEMA)}.${ident(fnName)}() RETURNS trigger AS $$\nBEGIN\n`;
  // Ensure nocouuid and nc_created_at are set even if client sends NULL explicitly.
  ddl += `  IF NEW.${ident('nocouuid')} IS NULL THEN NEW.${ident('nocouuid')} := gen_random_uuid(); END IF;\n`;
  ddl += `  IF NEW.${ident('nc_created_at')} IS NULL THEN NEW.${ident('nc_created_at')} := now(); END IF;\n`;
  ddl += `  IF TG_OP = 'UPDATE' THEN\n    NEW.${ident('nc_updated_at')} := now();\n  END IF;\n`;

  for (const s of specs) {
    const col = slug(s.fieldName);
    // YYMMDD from created_at, and last 4 chars from record id fallback
    const idExpr =
      `(('${s.prefix.replace(/'/g, "''")}') || ` +
      `to_char((NEW.${ident('nc_created_at')})::timestamp, 'YYMMDD') || '-' || ` +
      `right(${recordIdFallbackExpr('NEW')}, 4))`;
    ddl += `  IF NEW.${ident(col)} IS NULL OR NEW.${ident(col)} = '' THEN\n    NEW.${ident(col)} := ${idExpr};\n  END IF;\n`;
  }
  ddl += `  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n`;
  ddl += `DROP TRIGGER IF EXISTS ${ident(fnName)} ON ${ident(POSTGRES_SCHEMA)}.${ident(tn)};\n`;
  ddl += `CREATE TRIGGER ${ident(fnName)} BEFORE INSERT OR UPDATE ON ${ident(POSTGRES_SCHEMA)}.${ident(tn)}\n  FOR EACH ROW EXECUTE FUNCTION ${ident(POSTGRES_SCHEMA)}.${ident(fnName)}();\n`;
}

  ddl += `COMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '001_tables.sql'), ddl, 'utf8');

  // 002_links.sql derived from authoritative schema (tablesDump has complete links)
  let linksSql = sqlHeader();
  linksSql += `BEGIN;\n`;
  for (const t of tables) {
    const a = slug(t.name);
    for (const f of (t.fields || [])) {
      if (f.type !== 'multipleRecordLinks') continue;
      const linkedTableId = f.options && f.options.linkedTableId;
      if (!linkedTableId) continue;
      const other = tableById(schema, linkedTableId);
      if (!other) continue;
      const b = slug(other.name);

      const linkFieldSlug = slug(f.name) || 'link';
      const jn = `_m2m_${a}_${b}_${linkFieldSlug}`;
      const aCol = `${a}_id`;
      const bCol = (a === b) ? `${b}1_id` : `${b}_id`;

      const prefersSingle = !!(f.options && f.options.prefersSingleRecordLink);
      const _fkBase = (slug(f.name) || 'link');
      const fkColName = (prefersSingle ? (_fkBase.endsWith('_id') ? _fkBase : (_fkBase + '_id')) : null);

      junctions.push({ jn, a, b, aCol, bCol, linkFieldSlug, linkFieldId: f.id, prefersSingle, fkColName });

      linksSql += `\nCREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(jn)} (\n  ${ident(aCol)} bigint NOT NULL,\n  ${ident(bCol)} bigint NOT NULL\n);\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + aCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(aCol)});\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + bCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(bCol)});\n`;
      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)}\n  ADD CONSTRAINT ${ident(jn + '_' + aCol + '_fk')} FOREIGN KEY (${ident(aCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(a)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;
      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)}\n  ADD CONSTRAINT ${ident(jn + '_' + bCol + '_fk')} FOREIGN KEY (${ident(bCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(b)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;

      // For "preferred single" links, maintain the junction table from the FK column and vice versa.
      if (prefersSingle && fkColName) {
        // Ensure only one row per source record in the junction (1:0/1 semantics).
        linksSql += `CREATE UNIQUE INDEX IF NOT EXISTS ${ident(jn + '_' + aCol + '_uniq')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(aCol)});\n`;

        const fnA = `sync_${a}_${fkColName}_to_${jn}`;
        const trgA = `trg_${a}_${fkColName}_to_${jn}`;
        linksSql += `
CREATE OR REPLACE FUNCTION ${ident(POSTGRES_SCHEMA)}.${ident(fnA)}()
RETURNS trigger LANGUAGE plpgsql AS $$
BEGIN
  -- prevent recursion when the junction trigger updates the base table
  IF pg_trigger_depth() > 1 THEN
    RETURN NEW;
  END IF;

  -- Keep junction in sync with the FK column
  DELETE FROM ${ident(POSTGRES_SCHEMA)}.${ident(jn)}
   WHERE ${ident(aCol)} = NEW.${ident('nocopk')};

  IF NEW.${ident(fkColName)} IS NOT NULL THEN
    INSERT INTO ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(aCol)}, ${ident(bCol)})
    VALUES (NEW.${ident('nocopk')}, NEW.${ident(fkColName)});
  END IF;

  RETURN NEW;
END $$;

DROP TRIGGER IF EXISTS ${ident(trgA)} ON ${ident(POSTGRES_SCHEMA)}.${ident(a)};
CREATE TRIGGER ${ident(trgA)}
AFTER INSERT OR UPDATE OF ${ident(fkColName)} ON ${ident(POSTGRES_SCHEMA)}.${ident(a)}
FOR EACH ROW EXECUTE FUNCTION ${ident(POSTGRES_SCHEMA)}.${ident(fnA)}();
`;

        const fnJ = `sync_${jn}_to_${a}_${fkColName}`;
        const trgJ = `trg_${jn}_to_${a}_${fkColName}`;
        linksSql += `
CREATE OR REPLACE FUNCTION ${ident(POSTGRES_SCHEMA)}.${ident(fnJ)}()
RETURNS trigger LANGUAGE plpgsql AS $$
DECLARE
  v_a bigint;
  v_b bigint;
BEGIN
  IF pg_trigger_depth() > 1 THEN
    RETURN COALESCE(NEW, OLD);
  END IF;

  IF TG_OP = 'DELETE' THEN
    v_a := OLD.${ident(aCol)};
    v_b := OLD.${ident(bCol)};
    UPDATE ${ident(POSTGRES_SCHEMA)}.${ident(a)}
       SET ${ident(fkColName)} = NULL
     WHERE ${ident('nocopk')} = v_a
       AND ${ident(fkColName)} = v_b;
    RETURN OLD;
  ELSE
    v_a := NEW.${ident(aCol)};
    v_b := NEW.${ident(bCol)};

    -- Enforce single link: drop any other rows for this source id
    DELETE FROM ${ident(POSTGRES_SCHEMA)}.${ident(jn)}
     WHERE ${ident(aCol)} = v_a
       AND ${ident(bCol)} <> v_b;

    UPDATE ${ident(POSTGRES_SCHEMA)}.${ident(a)}
       SET ${ident(fkColName)} = v_b
     WHERE ${ident('nocopk')} = v_a;

    RETURN NEW;
  END IF;
END $$;

DROP TRIGGER IF EXISTS ${ident(trgJ)} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)};
CREATE TRIGGER ${ident(trgJ)}
AFTER INSERT OR UPDATE OR DELETE ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}
FOR EACH ROW EXECUTE FUNCTION ${ident(POSTGRES_SCHEMA)}.${ident(fnJ)}();
`;
      }
    }
  }
  linksSql += `\nCOMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '002_links.sql'), linksSql, 'utf8');

  // 003_views.sql
  if (CREATE_VIEWS) {
    let vsql = sqlHeader();
    vsql += `BEGIN;\n`;
    for (const t of exportTables) vsql += `DROP VIEW IF EXISTS ${ident(POSTGRES_SCHEMA)}.${ident('v_' + slug(t.name))} CASCADE;\n`;
    vsql += '\n';

    for (const t of exportTables) {
      const a = slug(t.name);

      // primary field from tablesDump if present, else export schema
      const td = tablesDump ? tableById(tablesDump, t.id) : null;
      const pvId = (td && td.primaryFieldId) ? td.primaryFieldId : (t.primaryFieldId || null);
      const pvField = pvId ? (td ? findFieldById(td, pvId) : findFieldById(t, pvId)) : null;

      const pvSlug = pvField ? slug(pvField.name) : null;
      let primaryExpr = `t.${ident('nocopk')}::text`;
      if (pvField && !isComputedType(pvField.type) && pvField.type !== 'multipleRecordLinks') {
        if (pvField.type === 'singleRecordLink') primaryExpr = `COALESCE(t.${ident(pvSlug + '_id')}::text, t.${ident('nocopk')}::text)`;
        else primaryExpr = `COALESCE(t.${ident(pvSlug)}::text, t.${ident('nocopk')}::text)`;
      }

      const linkCols = [];
      for (const j of junctions.filter(x => x.a === a)) {
        const alias = `${a}__${j.b}__${j.linkFieldSlug}__ids`;
        linkCols.push(
          `(SELECT COALESCE(array_agg(j.${ident(j.bCol)} ORDER BY j.${ident(j.bCol)}), '{}'::bigint[]) ` +
          `FROM ${ident(POSTGRES_SCHEMA)}.${ident(j.jn)} j WHERE j.${ident(j.aCol)} = t.${ident('nocopk')}) AS ${ident(alias)}`
        );
      }

      vsql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)} AS\nSELECT\n  t.*,\n  ${literalText(`${POSTGRES_SCHEMA}.${a}`)}::text AS __table,\n  ${primaryExpr} AS __primary`;
      if (linkCols.length) vsql += `,\n  ${linkCols.join(',\n  ')}`;
      vsql += `\nFROM ${ident(POSTGRES_SCHEMA)}.${ident(a)} t;\n\n`;
    }

    vsql += `COMMIT;\n`;
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '003_views.sql'), vsql, 'utf8');
  }

  // 004_computed_views.sql compiled from tablesDump (authoritative)
  {
    let csql = sqlHeader();
    csql += `BEGIN;\n`;
    for (const t of exportTables) csql += `DROP VIEW IF EXISTS ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + slug(t.name))} CASCADE;\n`;
    csql += '\n';

    // Pre-index formula strings by table and field id
    const formulaByTableId = new Map(); // tableId -> Map(fieldId -> formula)
    for (const t of (tablesDump ? tablesDump.tables : [])) {
      const m = new Map();
      for (const f of (t.fields || [])) {
        if (f.type === 'formula' && f.options && f.options.formula) m.set(f.id, f.options.formula);
      }
      formulaByTableId.set(t.id, m);
    }

    // Memo for compiled formulas per table/field for base qualifier
    const compiledFormulaMemo = new Map(); // key `${tableSlug}:${fieldId}:${qual}` -> sql

    function compileFormulaFor(tableObj, fieldObj, qualifier, stack = []) {
      const key = `${slug(tableObj.name)}:${fieldObj.id}:${qualifier}`;
      if (compiledFormulaMemo.has(key)) return compiledFormulaMemo.get(key);

      // Recursion guard (cyclic formulas)
      if (stack.includes(fieldObj.id)) return 'NULL';
      const nextStack = stack.concat([fieldObj.id]);

      const map = tableFieldIdToCol.get(slug(tableObj.name)) || new Map();
      const physicalCols = physicalColsByTableSlug.get(slug(tableObj.name)) || new Set();
      const outColSlug = slug(fieldObj.name);
      const legacySlug = slug(`${fieldObj.name}_legacy`);
      const hasLegacy = physicalCols.has(legacySlug);
      const ctx = {
        qualifier,
        fieldIdToCol: map,
        fieldById: tableFieldById.get(tableObj.id) || new Map(),
        tableObj,
        outColSlug,
        legacySlug,
        hasLegacy,
        // Allow formula compiler to inline same-table formula references
        compileFormulaFor,
        currentFieldId: fieldObj.id,
        _formulaStack: nextStack,
      };
      const { sql } = compileFormulaExpr(fieldObj.options.formula, ctx);
      compiledFormulaMemo.set(key, sql);
      return sql;
    }

    const computedViewBlocks = new Map();

    for (const t of exportTables) {
      const a = slug(t.name);
      const td = tablesDump ? tableById(tablesDump, t.id) : null;
      const fields = td ? (td.fields || []) : [];
      const computed = fields.filter(f => isComputedType(f.type));

      let viewBlock = '';
      if (!computed.length) {
        viewBlock = `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + a)} AS SELECT * FROM ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)};\n\n`;
      } else {
        const lookupExprs = [];
        const formulaExprs = [];
        for (const f of computed) {
          const outAlias = slug(f.name) || 'computed';
          const outCol = ident(outAlias);

          if (f.type === 'formula') {
            // If this is an Airtable-style autogenerated *_id formula that we materialize as a real column
            // on the base table (via 001_tables.sql + triggers), do NOT re-emit it in vc_* (comp.* already includes it).
            const autoSpec = autogenIdSpec(f, td.name);
            if (autoSpec) {
              viewBlock += `-- materialized autogen id: ${td.name}.${f.name}\n`;
              continue;
            }

            const compiled = compileFormulaFor(td, f, 'comp');
            if (compiled === 'NULL') viewBlock += `-- TODO(formula): ${td.name}.${f.name} (unsupported)\n`;
            formulaExprs.push(`(${compiled}) AS ${outCol}`);
            continue;
          }

          if (f.type === 'lookup' || f.type === 'multipleLookupValues' || f.type === 'rollup') {
            const opts = f.options || {};
            const linkFieldId = opts.recordLinkFieldId;
            const targetFieldId = opts.fieldIdInLinkedTable;
            if (!linkFieldId || !targetFieldId) { lookupExprs.push(`${emptyArrayForPgScalar('text')} AS ${outCol}`); continue; }

            const linkField = findFieldById(td, linkFieldId);
            if (!linkField || linkField.type !== 'multipleRecordLinks' || !linkField.options || !linkField.options.linkedTableId) {
              lookupExprs.push(`${emptyArrayForPgScalar('text')} AS ${outCol}`); continue;
            }

            const other = tableById(tablesDump, linkField.options.linkedTableId);
            if (!other) { lookupExprs.push(`${emptyArrayForPgScalar('text')} AS ${outCol}`); continue; }

            const otherSlug = slug(other.name);
            const otherFields = other.fields || [];
            const targetField = findFieldById(other, targetFieldId);
            if (!targetField) { lookupExprs.push(`${emptyArrayForPgScalar('text')} AS ${outCol}`); continue; }

            const linkSlug = slug(linkField.name);
            const joinTable = m2mJoinName(a, linkSlug, otherSlug);
            const leftFk = `${a}_id`;
            const rightFk = (a === otherSlug) ? `${otherSlug}1_id` : `${otherSlug}_id`;

            const otherPhysical = physicalColsByTableSlug.get(otherSlug) || new Set();
            const isTargetPhysical = otherPhysical.has(slug(targetField.name));
            const isTargetComputed = isComputedType(targetField.type) || !isTargetPhysical;

            // IMPORTANT: if the lookup targets a computed field, join the computed view vc_<other>
            const otherRel = (otherSlug === a)
              ? `${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)}`
              : (isTargetComputed ? `${ident(POSTGRES_SCHEMA)}.${ident('vc_' + otherSlug)}` : `${ident(POSTGRES_SCHEMA)}.${ident(otherSlug)}`);
            // Self-link lookups that target computed fields (lookup/rollup/formula) cannot safely join vc_<table>
            // inside vc_<table> creation (vc doesn't exist yet). Joining v_<table> also won't have the computed column.
            // Skip these (emit empty array) to avoid recursive/self-reference errors.
            if (otherSlug === a && isTargetComputed) {
              viewBlock += `-- TODO(lookup): ${td.name}.${f.name} targets computed field ${other.name}.${targetField.name} via self-link; skipped\n`;
              lookupExprs.push(`${emptyArrayForPgScalar('text')} AS ${outCol}`);
              continue;
            }
                        
            // Special case: lookup targets a link field (multipleRecordLinks). Airtable returns the
            // linked record display values (primary field), not the raw link IDs. Since links are
            // represented physically via junction tables, expand the lookup across the link's m2m.
            if (targetField.type === 'multipleRecordLinks' && targetField.options && targetField.options.linkedTableId) {
              const linked = tableById(tablesDump, targetField.options.linkedTableId);
              if (!linked) { lookupExprs.push(`${emptyArrayForPgScalar('text')} AS ${outCol}`); continue; }
            
              const linkedSlug = slug(linked.name);
              const link2Slug = slug(targetField.name);
              const joinTable2 = m2mJoinName(otherSlug, link2Slug, linkedSlug);
            
              const leftFk2 = `${otherSlug}_id`;
              const rightFk2 = (otherSlug === linkedSlug) ? `${linkedSlug}1_id` : `${linkedSlug}_id`;
            
              const linkedPrimary = findFieldById(linked, linked.primaryFieldId) || (linked.fields || [])[0];
              let linkedExpr = '';
              if (linkedPrimary && linkedPrimary.type === 'formula') {
                linkedExpr = compileFormulaFor(linked, linkedPrimary, 'ltbl');
              } else {
                // Fall back to "name" if we can't resolve the primary field for any reason.
                const primSlug = slug((linkedPrimary && linkedPrimary.name) ? linkedPrimary.name : 'name');
                linkedExpr = `ltbl.${ident(primSlug)}`;
              }
            
              const emptyArr = emptyArrayForPgScalar('text');
              const aggExpr = castForArrayAgg(linkedExpr, 'text');
              lookupExprs.push(
                `(SELECT COALESCE(array_agg(${aggExpr} ORDER BY ltbl.${ident('nocopk')}), ${emptyArr}) ` +
                `FROM ${ident(POSTGRES_SCHEMA)}.${ident(joinTable)} j ` +
                `JOIN ${ident(POSTGRES_SCHEMA)}.${ident(joinTable2)} j2 ON j2.${ident(leftFk2)} = j.${ident(rightFk)} ` +
                `JOIN ${ident(POSTGRES_SCHEMA)}.${ident(linkedSlug)} ltbl ON ltbl.${ident('nocopk')} = j2.${ident(rightFk2)} ` +
                `WHERE j.${ident(leftFk)} = base.${ident('nocopk')}) AS ${outCol}`
              );
              continue;
            }
            
            let targetExpr = '';
            if (targetField.type === 'formula') {
              targetExpr = compileFormulaFor(other, targetField, 'btbl');
            } else {
              // physical or computed view column
              targetExpr = `btbl.${ident(slug(targetField.name))}`;
            }

            // rollup without aggregation => treat as lookup array
            // rollup with aggregation => TODO (not implemented here)
            if (targetField.type === 'rollup' && targetField.options && targetField.options.rollupFunction) {
              // For now, preserve as TODO; most of your rollups are exposed as lookups.
              lookupExprs.push(`${emptyArrayForPgScalar('text')} AS ${outCol}`);
              continue;
            }

            // Pick an empty-array type compatible with the scalar type being aggregated.
            // If we can't infer a reliable scalar type (computed targets), fall back to text.
            let scalarType = pgTypeForField(targetField);
            if (!scalarType) scalarType = 'text';
            // For safety, force computed targets to text (avoids nested arrays / unknown types).
            if (isTargetComputed) scalarType = 'text';
            const emptyArr = emptyArrayForPgScalar(scalarType);

            const aggExpr = castForArrayAgg(targetExpr, scalarType);
            lookupExprs.push(
              `(SELECT COALESCE(array_agg(${aggExpr} ORDER BY btbl.${ident('nocopk')}), ${emptyArr}) ` +
              `FROM ${ident(POSTGRES_SCHEMA)}.${ident(joinTable)} j ` +
              `JOIN ${otherRel} btbl ON btbl.${ident('nocopk')} = j.${ident(rightFk)} ` +
              `WHERE j.${ident(leftFk)} = base.${ident('nocopk')}) AS ${outCol}`
            );
            continue;
          }

          // default
          lookupExprs.push(`NULL AS ${outCol}`);
        }

        viewBlock += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + a)} AS\nWITH comp AS (\n  SELECT base.*${lookupExprs.length ? ',\n    ' + lookupExprs.join(',\n    ') : ''}\n  FROM ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)} base\n)\nSELECT comp.*${formulaExprs.length ? ',\n  ' + formulaExprs.join(',\n  ') : ''}\nFROM comp;\n\n`;
      }

      computedViewBlocks.set('vc_' + a, viewBlock);
    }

    // Order computed views by their actual SQL dependencies (references to other vc_* views)
    function topoOrderComputedViews(blocksMap) {
      const names = Array.from(blocksMap.keys());
      const deps = new Map();
      for (const n of names) deps.set(n, new Set());
      for (const [n, b] of blocksMap.entries()) {
        const refs = (b.match(/"public"\."(vc_[^"]+)"/g) || []).map(x => x.replace(/.*"(vc_[^"]+)".*/, '$1'));
        for (const r of refs) {
          if (r !== n && blocksMap.has(r)) deps.get(n).add(r);
        }
      }
      const pos = new Map();
      let i = 0;
      for (const n of names) pos.set(n, i++);
      const incoming = new Map();
      for (const n of names) incoming.set(n, new Set(deps.get(n)));
      const ready = names.filter(n => incoming.get(n).size === 0);
      const ordered = [];
      while (ready.length) {
        ready.sort((a, b) => pos.get(a) - pos.get(b));
        const n = ready.shift();
        ordered.push(n);
        for (const m of names) {
          if (incoming.get(m).has(n)) {
            incoming.get(m).delete(n);
            if (incoming.get(m).size === 0 && !ordered.includes(m) && !ready.includes(m)) ready.push(m);
          }
        }
      }
      // If cycle, append remaining in original order
      for (const n of names) if (!ordered.includes(n)) ordered.push(n);
      return ordered;
    }

    const orderedViews = topoOrderComputedViews(computedViewBlocks);
    for (const n of orderedViews) csql += computedViewBlocks.get(n);


    csql += `COMMIT;\n`;
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '004_computed_views.sql'), csql, 'utf8');
  }

  // 010_load.sql + csv/*.csv (host-run \copy)
  if (AIRTABLE_EXPORT_DIR && fs.existsSync(AIRTABLE_EXPORT_DIR)) {
    const csvDir = path.join(POSTGRES_OUT_DIR, 'csv');
    ensureDir(csvDir);

    const loadSql = [];
    loadSql.push(sqlHeader());
    loadSql.push('\\set ON_ERROR_STOP on\n');
    loadSql.push('BEGIN;\n');
    loadSql.push(`SET search_path TO ${ident(POSTGRES_SCHEMA)};\n`);

    for (const t of exportTables) {
      const tableName = t.name;
      const tableSlug = slug(tableName);
      const fp = findTableFile(AIRTABLE_EXPORT_DIR, tableName);
      if (!fp) continue;

      const data = readJson(fp);
      const rowsRaw = Array.isArray(data) ? data : (data.records || data.rows || []);
      if (!Array.isArray(rowsRaw) || rowsRaw.length === 0) continue;

      const storedFields = (t.fields || []).filter(f =>
        !isComputedType(f.type) &&
        f.type !== 'multipleRecordLinks' &&
        f.type !== 'singleRecordLink' &&
        f.type !== 'button'
      );
      const storedColSlugs = storedFields.map(f => slug(f.name)).filter(Boolean);
      const cols = ['airtable_id', ...storedColSlugs];

      const rows = rowsRaw.map(r => {
        const out = {};
        const airtableId = r.id || r.airtable_id || r.recordId || null;
        if (!airtableId) return null;
        out.airtable_id = airtableId;
        const fieldsObj = (r.fields && typeof r.fields === 'object') ? r.fields : r;
        for (const f of storedFields) {
          const kk = slug(f.name);
          let v = fieldsObj[f.name];
          if (v === undefined) continue;
          if (v && typeof v === 'object') v = JSON.stringify(v);
          out[kk] = v;
        }
        for (const c of cols) if (!(c in out)) out[c] = '';
        return out;
      }).filter(Boolean);

      if (!rows.length) continue;

      const csvPath = writeCsv(csvDir, tableSlug, cols, rows);
      const rel = path.relative(POSTGRES_OUT_DIR, csvPath).replace(/\\/g,'/');
      loadSql.push(`\\copy ${ident(tableSlug)}(${cols.map(ident).join(',')}) FROM ${rel} WITH (FORMAT csv, HEADER true);\n`);
    }

    // Junction CSVs are still derived from export record JSON
    for (const t of exportTables) {
      const aName = t.name;
      const a = slug(aName);
      const fp = findTableFile(AIRTABLE_EXPORT_DIR, aName);
      if (!fp) continue;

      const data = readJson(fp);
      const rowsRaw = Array.isArray(data) ? data : (data.records || data.rows || []);
      if (!Array.isArray(rowsRaw) || rowsRaw.length === 0) continue;

      const linkFields = (t.fields || []).filter(f => f.type === 'multipleRecordLinks' && f.options && f.options.linkedTableId);
      for (const f of linkFields) {
        const other = tableById(exportSchema, f.options.linkedTableId);
        if (!other) continue;
        const b = slug(other.name);

        const linkFieldSlug = slug(f.name) || 'link';
        const jn = `_m2m_${a}_${b}_${linkFieldSlug}`;
        const rawName = `${jn}__raw`;
        const cols = ['a_airtable_id', 'b_airtable_id'];
        const aCol = `${a}_id`;
        const bCol = (a === b) ? `${b}1_id` : `${b}_id`;

        const jrows = [];
        for (const r of rowsRaw) {
          const aId = r.id || r.airtable_id || r.recordId || null;
          if (!aId) continue;
          const fieldsObj = (r.fields && typeof r.fields === 'object') ? r.fields : r;
          const linked = fieldsObj[f.name];
          if (!linked) continue;
          const linkedIds = Array.isArray(linked) ? linked : [linked];
          for (const bId of linkedIds) {
            if (!bId) continue;
            jrows.push({ a_airtable_id: aId, b_airtable_id: bId });
          }
        }
        if (!jrows.length) continue;

        const csvPath = writeCsv(csvDir, rawName, cols, jrows);
        const relJ = path.relative(POSTGRES_OUT_DIR, csvPath).replace(/\\/g,'/');
        loadSql.push(`\n-- Link field: ${aName}.${f.name} -> ${other.name}\n`);
        loadSql.push(`CREATE TEMP TABLE ${ident(rawName)}(${ident('a_airtable_id')} text, ${ident('b_airtable_id')} text);\n`);
        loadSql.push(`\\copy ${ident(rawName)}(${cols.map(ident).join(',')}) FROM ${relJ} WITH (FORMAT csv, HEADER true);\n`);
        loadSql.push(`INSERT INTO ${ident(jn)}(${ident(aCol)}, ${ident(bCol)})\n`);
        loadSql.push(`SELECT a.nocopk, b.nocopk\nFROM ${ident(rawName)} r\nJOIN ${ident(a)} a ON a.airtable_id = r.a_airtable_id\nJOIN ${ident(b)} b ON b.airtable_id = r.b_airtable_id;\n`);
        loadSql.push(`DROP TABLE ${ident(rawName)};\n`);
      }
    }

    loadSql.push('COMMIT;\n');
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '010_load.sql'), loadSql.join(''), 'utf8');
  }

  console.log('[OK] Wrote Postgres artifacts to:', POSTGRES_OUT_DIR);
  console.log(' - 001_tables.sql');
  console.log(' - 002_links.sql');
  console.log(' - 003_views.sql');
  console.log(' - 004_computed_views.sql (from tables_dump.json when present)');
  console.log(' - 010_load.sql + csv/*.csv');
}

main();
