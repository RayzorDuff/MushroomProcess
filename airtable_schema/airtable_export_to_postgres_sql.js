#!/usr/bin/env node
require('./load_env');
/**
 * airtable_export_to_postgres_sql.js
 *
 * Generate Postgres SQL (tables + constraints + optional computed views) from an airtable-export schema.
 *
 * Goals:
 *  - Create base tables for STORED fields only (no lookup/rollup/formula as physical columns)
 *  - Represent links:
 *      - singleRecordLink: <field>_id BIGINT (references other.nocopk)
 *      - multipleRecordLinks: junction table _m2m_<a>_<b>_<field>(<a>_id, <b>_id) with FKs
 *  - Provide "presentation" views v_<table> that add:
 *      - __table, __primary (best-effort from primaryFieldId)
 *      - link arrays for junction links
 *  - Emit CSV loader script (\copy) when AIRTABLE_EXPORT_DIR is provided (best-effort).
 *
 * This script is a practical first step toward direct airtable-export -> SQL without NocoDB meta APIs.
 *
 * Usage:
 *   node airtable_export_to_postgres_sql.js
 *
 * Env:
 *   AIRTABLE_SCHEMA_PATH=./_schema.json
 *   POSTGRES_SCHEMA=public
 *   POSTGRES_OUT_DIR=./pg_out
 *   AIRTABLE_EXPORT_DIR=./export   (optional; if set, generate CSVs + 010_load.sql)
 *   CREATE_VIEWS=true              (default true)
 *   BIGINT_PKS=true                (default true; creates nocopk BIGSERIAL PK; also stores airtable_id)
 */
const fs = require('fs');
const path = require('path');

function envBool(name, defVal) {
  const v = (process.env[name] ?? '').toString().trim();
  if (!v) return defVal;
  return /^true|1|yes|y$/i.test(v);
}

const AIRTABLE_EXPORT_DIR = process.env.AIRTABLE_EXPORT_DIR || '';
const AIRTABLE_SCHEMA_PATH = process.env.AIRTABLE_SCHEMA_PATH ||  path.join(AIRTABLE_EXPORT_DIR, '_schema.json');
const POSTGRES_SCHEMA = (process.env.POSTGRES_SCHEMA || 'public').toString();
const POSTGRES_OUT_DIR = process.env.POSTGRES_OUT_DIR || './pg_out';
const CREATE_VIEWS = envBool('CREATE_VIEWS', true);
const BIGINT_PKS = envBool('BIGINT_PKS', true);

function die(msg) {
  console.error('[ERROR]', msg);
  process.exit(1);
}

function readJson(p) {
  return JSON.parse(fs.readFileSync(p, 'utf8'));
}

function ident(name) {
  return '"' + String(name).replace(/"/g, '""') + '"';
}
function slug(name) {
  return String(name).toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, '');
}

function pgTypeForField(f) {
  const t = f.type;
  if (t === 'checkbox') return 'boolean';
  if (t === 'number' || t === 'currency' || t === 'percent' || t === 'rating') return 'numeric';
  if (t === 'count') return 'bigint';
  if (t === 'date') return 'date';
  if (t === 'dateTime' || t === 'createdTime' || t === 'lastModifiedTime') return 'timestamp without time zone';
  if (t === 'duration') return 'numeric';
  if (t === 'phoneNumber' || t === 'email' || t === 'url' || t === 'barcode') return 'text';
  if (t === 'singleSelect' || t === 'multipleSelects') return 'text';
  if (t === 'multilineText' || t === 'richText' || t === 'singleLineText') return 'text';
  if (t === 'attachment' || t === 'multipleAttachments') return 'jsonb';
  if (t === 'multipleRecordLinks') return null;
  if (t === 'singleRecordLink') return 'bigint';
  if (t === 'lookup' || t === 'multipleLookupValues' || t === 'rollup' || t === 'formula') return null;
  if (t === 'autoNumber') return 'bigint';
  if (t === 'collaborator' || t === 'multipleCollaborators') return 'text';
  if (t === 'button') return null;
  if (t === 'aiText') return 'text';
  return 'text';
}

function isComputed(f) {
  return ['lookup','multipleLookupValues','rollup','formula'].includes(f.type);
}

function primaryFieldId(table) {
  return table.primaryFieldId || null;
}

function findFieldById(table, fid) {
  return (table.fields || []).find(x => x.id === fid);
}

function tableById(schema, tid) {
  return (schema.tables || []).find(t => t.id === tid);
}

function ensureDir(p) {
  fs.mkdirSync(p, { recursive: true });
}

function sqlHeader() {
  return `-- Generated by airtable_export_to_postgres_sql.js\n-- ${new Date().toISOString()}\n`;
}

function main() {
  if (!fs.existsSync(AIRTABLE_SCHEMA_PATH)) die(`Missing AIRTABLE_SCHEMA_PATH: ${AIRTABLE_SCHEMA_PATH}`);
  const schema = readJson(AIRTABLE_SCHEMA_PATH);
  ensureDir(POSTGRES_OUT_DIR);

  const tables = schema.tables || [];
  if (!tables.length) die('Schema has no tables');

  // 001_tables.sql
  let ddl = sqlHeader();
  ddl += `BEGIN;\nCREATE SCHEMA IF NOT EXISTS ${ident(POSTGRES_SCHEMA)};\n`;
  ddl = `-- Requires extension pgcrypto for gen_random_uuid()\nCREATE EXTENSION IF NOT EXISTS pgcrypto;\n\n` + ddl;

  const junctions = [];

  for (const t of tables) {
    const tn = slug(t.name);
    const cols = [];
    if (BIGINT_PKS) {
      cols.push(`${ident('nocopk')} BIGSERIAL PRIMARY KEY`);
    } else {
      cols.push(`${ident('airtable_id')} text PRIMARY KEY`);
    }
    cols.push(`${ident('nocouuid')} uuid DEFAULT gen_random_uuid()`);
    cols.push(`${ident('airtable_id')} text UNIQUE`);
    cols.push(`${ident('nc_created_at')} timestamp without time zone DEFAULT now()`);
    cols.push(`${ident('nc_updated_at')} timestamp without time zone DEFAULT now()`);

    const reserved = new Set(['nocopk','nocouuid','airtable_id','nc_created_at','nc_updated_at']);

    for (const f of (t.fields || [])) {
      if (isComputed(f)) continue;
      if (f.type === 'multipleRecordLinks') continue;
      if (f.type === 'button') continue;

      const baseName = slug(f.name);
      if (!baseName || reserved.has(baseName)) continue;

      if (f.type === 'singleRecordLink') {
        cols.push(`${ident(baseName + '_id')} bigint`);
        continue;
      }

      const typ = pgTypeForField(f) || 'text';
      cols.push(`${ident(baseName)} ${typ}`);
    }

    ddl += `\nCREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(tn)} (\n  ${cols.join(',\n  ')}\n);\n`;
  }
  ddl += `COMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '001_tables.sql'), ddl, 'utf8');

  // 002_links.sql
  let linksSql = sqlHeader() + `BEGIN;\n`;

  for (const t of tables) {
    const a = slug(t.name);
    for (const f of (t.fields || [])) {
      if (f.type !== 'multipleRecordLinks') continue;
      const otherTid = (f.options && f.options.linkedTableId) ? f.options.linkedTableId : null;
      if (!otherTid) continue;
      const other = tableById(schema, otherTid);
      if (!other) continue;
      const b = slug(other.name);

      const jn = `_m2m_${a}_${b}_${slug(f.name) || 'link'}`;
      const aCol = `${a}_id`;
      const bCol = `${b}_id`;
      junctions.push({ jn, a, b, aCol, bCol });

      linksSql += `\nCREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(jn)} (\n  ${ident(aCol)} bigint NOT NULL,\n  ${ident(bCol)} bigint NOT NULL\n);\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + aCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(aCol)});\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + bCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(bCol)});\n`;
      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)} ADD CONSTRAINT ${ident(jn + '_' + aCol + '_fk')} FOREIGN KEY (${ident(aCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(a)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;
      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)} ADD CONSTRAINT ${ident(jn + '_' + bCol + '_fk')} FOREIGN KEY (${ident(bCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(b)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;
    }
  }

  linksSql += `\nCOMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '002_links.sql'), linksSql, 'utf8');

  // 003_views.sql
  if (CREATE_VIEWS) {
    let vsql = sqlHeader() + `BEGIN;\n`;
    for (const t of tables) {
      vsql += `DROP VIEW IF EXISTS ${ident(POSTGRES_SCHEMA)}.${ident('v_' + slug(t.name))} CASCADE;\n`;
    }
    vsql += '\n';

    for (const t of tables) {
      const base = slug(t.name);
      const pvId = primaryFieldId(t);
      const pvField = pvId ? findFieldById(t, pvId) : null;
      const pvSlug = pvField ? slug(pvField.name) : null;

      let primaryExpr = `t.${ident('nocopk')}::text`;
      if (pvField) {
        if (pvField.type === 'singleRecordLink') {
          primaryExpr = `COALESCE(t.${ident(pvSlug + '_id')}::text, t.${ident('nocopk')}::text)`;
        } else if (!isComputed(pvField) && pvField.type !== 'multipleRecordLinks') {
          primaryExpr = `COALESCE(t.${ident(pvSlug)}::text, t.${ident('nocopk')}::text)`;
        }
      }

      const linkCols = [];
      for (const j of junctions.filter(x => x.a === base)) {
        linkCols.push(`(SELECT COALESCE(array_agg(j.${ident(j.bCol)} ORDER BY j.${ident(j.bCol)}), '{}'::bigint[]) FROM ${ident(POSTGRES_SCHEMA)}.${ident(j.jn)} j WHERE j.${ident(j.aCol)} = t.${ident('nocopk')}) AS ${ident(base + '__' + j.b + '__ids')}`);
      }

      vsql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('v_' + base)} AS\nSELECT\n  t.*,\n  ${ident(POSTGRES_SCHEMA + '.' + base)}::text AS __table,\n  ${primaryExpr} AS __primary`;
      if (linkCols.length) vsql += `,\n  ${linkCols.join(',\n  ')}`;
      vsql += `\nFROM ${ident(POSTGRES_SCHEMA)}.${ident(base)} t;\n\n`;
    }

    vsql += `COMMIT;\n`;
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '003_views.sql'), vsql, 'utf8');
  }

  // 010_load.sql + csv
  if (AIRTABLE_EXPORT_DIR && fs.existsSync(AIRTABLE_EXPORT_DIR)) {
    const csvDir = path.join(POSTGRES_OUT_DIR, 'csv');
    ensureDir(csvDir);

    const load = [sqlHeader(), `\\set ON_ERROR_STOP on\nBEGIN;\nSET search_path TO ${ident(POSTGRES_SCHEMA)};\n`];

    function writeCsv(tableSlug, rows) {
      const cols = Object.keys(rows[0] || {});
      const csvPath = path.join(csvDir, `${tableSlug}.csv`);
      const esc = (v) => {
        if (v === null || v === undefined) return '';
        const s = String(v);
        if (/[",\n\r]/.test(s)) return '"' + s.replace(/"/g,'""') + '"';
        return s;
      };
      const lines = [cols.map(esc).join(',')];
      for (const r of rows) lines.push(cols.map(c => esc(r[c])).join(','));
      fs.writeFileSync(csvPath, lines.join('\n'), 'utf8');
      return { cols, csvPath };
    }

    for (const t of tables) {
      const tableSlug = slug(t.name);
      const candidates = [
        path.join(AIRTABLE_EXPORT_DIR, `${tableSlug}.json`),
        path.join(AIRTABLE_EXPORT_DIR, `${t.name}.json`),
        path.join(AIRTABLE_EXPORT_DIR, `${t.name}.records.json`),
      ];
      const fp = candidates.find(p => fs.existsSync(p));
      if (!fp) continue;

      const data = readJson(fp);
      const rows = Array.isArray(data) ? data : (data.records || data.rows || []);
      if (!Array.isArray(rows) || rows.length === 0) continue;

      const normalized = rows.map(r => {
        const out = {};
        const airtableId = r.id || r.airtable_id || r.recordId || null;
        if (airtableId) out.airtable_id = airtableId;
        if (r.fields && typeof r.fields === 'object') {
          for (const [k,v] of Object.entries(r.fields)) {
            const kk = slug(k);
            out[kk] = (v && typeof v === 'object') ? JSON.stringify(v) : v;
          }
        } else {
          for (const [k,v] of Object.entries(r)) {
            if (k === 'id' || k === 'airtable_id') continue;
            out[slug(k)] = (v && typeof v === 'object') ? JSON.stringify(v) : v;
          }
        }
        return out;
      });

      const { cols, csvPath } = writeCsv(tableSlug, normalized);
      load.push(`\\copy ${ident(tableSlug)}(${cols.map(ident).join(',')}) FROM '${path.relative(POSTGRES_OUT_DIR, csvPath).replace(/\\/g,'/')}' WITH (FORMAT csv, HEADER true);\n`);
    }

    load.push('COMMIT;\n');
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '010_load.sql'), load.join(''), 'utf8');
  }

  console.log('[OK] Wrote Postgres artifacts to:', POSTGRES_OUT_DIR);
  console.log(' - 001_tables.sql');
  console.log(' - 002_links.sql');
  if (CREATE_VIEWS) console.log(' - 003_views.sql');
  if (AIRTABLE_EXPORT_DIR) console.log(' - 010_load.sql + csv/*.csv (best-effort)');
}

main();
