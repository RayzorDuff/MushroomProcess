#!/usr/bin/env node
require('./load_env');
/**
 * Script: airtable_export_to_postgres_sql.js
 * Version: 2026-01-25.2
 * =============================================================================
 *  Copyright © 2025 Dank Mushrooms, LLC
 *  Licensed under the GNU General Public License v3 (GPL-3.0-only)
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 3 of the License.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with this program. If not, see <https://www.gnu.org/licenses/>.
 * =============================================================================

 * Goals:
 *  - Create base tables for STORED fields only (no lookup/rollup/formula as physical columns)
 *  - Represent links:
 *      - singleRecordLink: <field>_id BIGINT (references other.nocopk)
 *      - multipleRecordLinks: junction table _m2m_<a>_<b>_<field>(<a>_id, <b>_id) with FKs
 *  - Provide "presentation" views v_<table> that add:
 *      - __table, __primary (best-effort from primaryFieldId)
 *      - link arrays for junction links
 *  - Emit CSV loader script (\copy) when AIRTABLE_EXPORT_DIR is provided (best-effort).
 *
 * Outputs into POSTGRES_OUT_DIR:
 *   001_tables.sql            Base tables with STORED fields only (no lookup/rollup/formula as physical cols)
 *   002_links.sql             Junction tables + FK constraints for multipleRecordLinks
 *   003_views.sql             v_<table> views with __table, __primary (best-effort) and link id arrays
 *   004_computed_views.sql    vc_<table> views that add lookup/rollup scaffolding as array_agg (best-effort)
 *   010_load.sql + csv/*.csv  Relational CSV + loader (base tables + junction resolution via airtable_id)
 *
 * Notes:
 *  - We avoid relying on NocoDB meta APIs entirely.
 *  - multipleRecordLinks are exported into junction tables (CSV) and resolved by airtable_id -> nocopk during load.
 *  - singleRecordLink loading is NOT implemented yet (needs mapping logic similar to junctions); we currently skip.
 *  - rollup aggregation formula is not present in airtable-export output, so rollups are emitted as array_agg with TODO.
 * Usage:
 *   node airtable_export_to_postgres_sql.js
 *
 * Env:
 *   AIRTABLE_SCHEMA_PATH=./_schema.json
 *   POSTGRES_SCHEMA=public
 *   POSTGRES_OUT_DIR=./pg_out
 *   AIRTABLE_EXPORT_DIR=./export     (optional; directory with per-table JSON exports)
 *   CREATE_VIEWS=true              (default true)
 *   BIGINT_PKS=true                 (default true; creates nocopk BIGSERIAL PK and stores airtable_id)
 */

const fs = require('fs');
const path = require('path');

function envBool(name, defVal) {
  const v = (process.env[name] ?? '').toString().trim();
  if (!v) return defVal;
  return /^true|1|yes|y$/i.test(v);
}

const AIRTABLE_EXPORT_DIR = process.env.AIRTABLE_EXPORT_DIR || '';
const AIRTABLE_SCHEMA_PATH = process.env.AIRTABLE_SCHEMA_PATH ||  path.join(AIRTABLE_EXPORT_DIR, '_schema.json');
const POSTGRES_SCHEMA = (process.env.POSTGRES_SCHEMA || 'public').toString();
const POSTGRES_OUT_DIR = process.env.POSTGRES_OUT_DIR || './pg_out';
const CREATE_VIEWS = envBool('CREATE_VIEWS', true);
const BIGINT_PKS = envBool('BIGINT_PKS', true);

function die(msg) {
  console.error('[ERROR]', msg);
  process.exit(1);
}
function readJson(p) {
  return JSON.parse(fs.readFileSync(p, 'utf8'));
}
function ensureDir(p) {
  fs.mkdirSync(p, { recursive: true });
}
function ident(name) {
  return '"' + String(name).replace(/"/g, '""') + '"';
}
function slug(name) {
  return String(name).toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, '');
}
function sqlHeader() {
  return `-- Generated by airtable_export_to_postgres_sql_v2.js\n-- ${new Date().toISOString()}\n`;
}

function pgTypeForField(f) {
  const t = f.type;
  if (t === 'checkbox') return 'boolean';
  if (t === 'number' || t === 'currency' || t === 'percent' || t === 'rating') return 'numeric';
  if (t === 'count') return 'bigint';
  if (t === 'date') return 'date';
  if (t === 'dateTime' || t === 'createdTime' || t === 'lastModifiedTime') return 'timestamp without time zone';
  if (t === 'duration') return 'numeric';
  if (t === 'phoneNumber' || t === 'email' || t === 'url' || t === 'barcode') return 'text';
  if (t === 'singleSelect' || t === 'multipleSelects') return 'text';
  if (t === 'multilineText' || t === 'richText' || t === 'singleLineText') return 'text';
  if (t === 'attachment' || t === 'multipleAttachments') return 'jsonb';
  if (t === 'multipleRecordLinks') return null;
  if (t === 'singleRecordLink') return 'bigint';
  if (t === 'lookup' || t === 'multipleLookupValues' || t === 'rollup' || t === 'formula') return null;
  if (t === 'autoNumber') return 'bigint';
  if (t === 'collaborator' || t === 'multipleCollaborators') return 'text';
  if (t === 'button') return null;
  if (t === 'aiText') return 'text';
  return 'text';
}

function isComputed(f) {
  return ['lookup','multipleLookupValues','rollup','formula'].includes(f.type);
}
function tableById(schema, tid) {
  return (schema.tables || []).find(t => t.id === tid);
}
function primaryFieldId(table) {
  return table.primaryFieldId || null;
}
function findFieldById(table, fid) {
  return (table.fields || []).find(x => x.id === fid);
}

function findTableFile(dir, tableName) {
  const tableSlug = slug(tableName);
  const candidates = [
    path.join(dir, `${tableSlug}.json`),
    path.join(dir, `${tableName}.json`),
    path.join(dir, `${tableName}.records.json`),
  ];
  return candidates.find(p => fs.existsSync(p)) || '';
}

function writeCsv(csvDir, relName, cols, rows) {
  const csvPath = path.join(csvDir, `${relName}.csv`);
  const esc = (v) => {
    if (v === null || v === undefined) return '';
    const s = String(v);
    if (/[",\n\r]/.test(s)) return '"' + s.replace(/"/g,'""') + '"';
    return s;
  };
  const lines = [];
  lines.push(cols.map(esc).join(','));
  for (const r of rows) lines.push(cols.map(c => esc(r[c])).join(','));
  fs.writeFileSync(csvPath, lines.join('\n'), 'utf8');
  return csvPath;
}

function main() {
  if (!fs.existsSync(AIRTABLE_SCHEMA_PATH)) die(`Missing AIRTABLE_SCHEMA_PATH: ${AIRTABLE_SCHEMA_PATH}`);
  const schema = readJson(AIRTABLE_SCHEMA_PATH);
  const tables = schema.tables || [];
  if (!tables.length) die('Schema has no tables');

  ensureDir(POSTGRES_OUT_DIR);

  // FieldId maps per table (for computed compiler)
  const tableFieldById = new Map(); // tableId -> Map(fieldId -> field)
  for (const t of tables) {
    const m = new Map();
    for (const f of (t.fields || [])) m.set(f.id, f);
    tableFieldById.set(t.id, m);
  }

  // Track junctions created from multipleRecordLinks: {jn, a, b, aCol, bCol, linkFieldName}
  const junctions = [];

  // 001_tables.sql
  let ddl = sqlHeader();
  ddl = `-- Requires extension pgcrypto for gen_random_uuid()\nCREATE EXTENSION IF NOT EXISTS pgcrypto;\n\n` + ddl;
  ddl += `BEGIN;\nCREATE SCHEMA IF NOT EXISTS ${ident(POSTGRES_SCHEMA)};\n`;

  for (const t of tables) {
    const tn = slug(t.name);
    const cols = [];
    if (BIGINT_PKS) {
      cols.push(`${ident('nocopk')} BIGSERIAL PRIMARY KEY`);
    } else {
      cols.push(`${ident('airtable_id')} text PRIMARY KEY`);
    }
    cols.push(`${ident('nocouuid')} uuid DEFAULT gen_random_uuid()`);
    cols.push(`${ident('airtable_id')} text UNIQUE`);
    cols.push(`${ident('nc_created_at')} timestamp without time zone DEFAULT now()`);
    cols.push(`${ident('nc_updated_at')} timestamp without time zone DEFAULT now()`);

    const reserved = new Set(['nocopk','nocouuid','airtable_id','nc_created_at','nc_updated_at']);

    for (const f of (t.fields || [])) {
      if (isComputed(f)) continue;
      if (f.type === 'multipleRecordLinks') continue; // junction
      if (f.type === 'button') continue;

      const baseName = slug(f.name);
      if (!baseName || reserved.has(baseName)) continue;

      if (f.type === 'singleRecordLink') {
        // (Not loaded yet) - store FK by nocopk once mapping is implemented
        cols.push(`${ident(baseName + '_id')} bigint`);
        continue;
      }

      const typ = pgTypeForField(f) || 'text';
      cols.push(`${ident(baseName)} ${typ}`);
    }

    ddl += `\nCREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(tn)} (\n  ${cols.join(',\n  ')}\n);\n`;
  }

  ddl += `COMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '001_tables.sql'), ddl, 'utf8');

  // 002_links.sql
  let linksSql = sqlHeader();
  linksSql += `BEGIN;\n`;

  for (const t of tables) {
    const aName = t.name;
    const a = slug(aName);
    for (const f of (t.fields || [])) {
      if (f.type !== 'multipleRecordLinks') continue;
      const linkedTableId = f.options && f.options.linkedTableId;
      if (!linkedTableId) continue;
      const other = tableById(schema, linkedTableId);
      if (!other) continue;
      const bName = other.name;
      const b = slug(bName);

      const jn = `_m2m_${a}_${b}_${slug(f.name) || 'link'}`;
      const aCol = `${a}_id`;
      const bCol = (a === b) ? `${b}1_id` : `${b}_id`;

      junctions.push({ jn, a, b, aCol, bCol, linkFieldName: f.name });

      linksSql += `\nCREATE TABLE IF NOT EXISTS ${ident(POSTGRES_SCHEMA)}.${ident(jn)} (\n  ${ident(aCol)} bigint NOT NULL,\n  ${ident(bCol)} bigint NOT NULL\n);\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + aCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(aCol)});\n`;
      linksSql += `CREATE INDEX IF NOT EXISTS ${ident(jn + '_' + bCol + '_idx')} ON ${ident(POSTGRES_SCHEMA)}.${ident(jn)}(${ident(bCol)});\n`;

      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)}\n`;
      linksSql += `  ADD CONSTRAINT ${ident(jn + '_' + aCol + '_fk')} FOREIGN KEY (${ident(aCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(a)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;

      linksSql += `ALTER TABLE ${ident(POSTGRES_SCHEMA)}.${ident(jn)}\n`;
      linksSql += `  ADD CONSTRAINT ${ident(jn + '_' + bCol + '_fk')} FOREIGN KEY (${ident(bCol)}) REFERENCES ${ident(POSTGRES_SCHEMA)}.${ident(b)}(${ident('nocopk')}) DEFERRABLE INITIALLY DEFERRED;\n`;
    }
  }

  linksSql += `\nCOMMIT;\n`;
  fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '002_links.sql'), linksSql, 'utf8');

  // 003_views.sql
  if (CREATE_VIEWS) {
    let vsql = sqlHeader();
    vsql += `BEGIN;\n`;

    for (const t of tables) {
      vsql += `DROP VIEW IF EXISTS ${ident(POSTGRES_SCHEMA)}.${ident('v_' + slug(t.name))} CASCADE;\n`;
    }
    vsql += '\n';

    for (const t of tables) {
      const aName = t.name;
      const a = slug(aName);

      const pvId = primaryFieldId(t);
      const pvField = pvId ? findFieldById(t, pvId) : null;
      const pvSlug = pvField ? slug(pvField.name) : null;

      let primaryExpr = `t.${ident('nocopk')}::text`;
      if (pvField && !isComputed(pvField) && pvField.type !== 'multipleRecordLinks') {
        if (pvField.type === 'singleRecordLink') {
          primaryExpr = `COALESCE(t.${ident(pvSlug + '_id')}::text, t.${ident('nocopk')}::text)`;
        } else {
          primaryExpr = `COALESCE(t.${ident(pvSlug)}::text, t.${ident('nocopk')}::text)`;
        }
      }

      const linkCols = [];
      for (const j of junctions.filter(x => x.a === a)) {
        linkCols.push(
          `(SELECT COALESCE(array_agg(j.${ident(j.bCol)} ORDER BY j.${ident(j.bCol)}), '{}'::bigint[]) ` +
          `FROM ${ident(POSTGRES_SCHEMA)}.${ident(j.jn)} j WHERE j.${ident(j.aCol)} = t.${ident('nocopk')}) AS ${ident(a + '__' + j.b + '__ids')}`
        );
      }

      vsql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)} AS\n`;
      vsql += `SELECT\n  t.*,\n  ${ident(POSTGRES_SCHEMA + '.' + a)}::text AS __table,\n  ${primaryExpr} AS __primary`;
      if (linkCols.length) vsql += `,\n  ${linkCols.join(',\n  ')}`;
      vsql += `\nFROM ${ident(POSTGRES_SCHEMA)}.${ident(a)} t;\n\n`;
    }

    vsql += `COMMIT;\n`;
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '003_views.sql'), vsql, 'utf8');
  }

  // 004_computed_views.sql
  {
    let csql = sqlHeader();
    csql += `BEGIN;\n`;

    for (const t of tables) {
      csql += `DROP VIEW IF EXISTS ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + slug(t.name))} CASCADE;\n`;
    }
    csql += '\n';

    for (const t of tables) {
      const aName = t.name;
      const a = slug(aName);

      const computedFields = (t.fields || []).filter(f =>
        ['lookup','multipleLookupValues','rollup'].includes(f.type) &&
        f.options && f.options.recordLinkFieldId && f.options.fieldIdInLinkedTable
      );

      if (!computedFields.length) {
        csql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + a)} AS SELECT * FROM ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)};\n\n`;
        continue;
      }

      const exprs = [];
      for (const f of computedFields) {
        const linkFieldId = f.options.recordLinkFieldId;
        const targetFieldId = f.options.fieldIdInLinkedTable;

        const linkField = (tableFieldById.get(t.id) || new Map()).get(linkFieldId);
        if (!linkField || linkField.type !== 'multipleRecordLinks' || !linkField.options || !linkField.options.linkedTableId) {
          exprs.push(`NULL::text AS ${ident(slug(f.name) || 'computed')}`);
          continue;
        }

        const other = tableById(schema, linkField.options.linkedTableId);
        if (!other) {
          exprs.push(`NULL::text AS ${ident(slug(f.name) || 'computed')}`);
          continue;
        }
        const b = slug(other.name);

        const otherField = (tableFieldById.get(other.id) || new Map()).get(targetFieldId);
        if (!otherField) {
          exprs.push(`NULL::text AS ${ident(slug(f.name) || 'computed')}`);
          continue;
        }
        const targetSlug = slug(otherField.name);
        const jn = `_m2m_${a}_${b}_${slug(linkField.name) || 'link'}`;
        const outCol = ident(slug(f.name) || 'computed');

        if (f.type === 'rollup') {
          csql += `-- TODO(rollup): ${aName}.${f.name} (Airtable rollup aggregation formula not exported); emitted as array_agg\n`;
        }

        const expr =
          `(SELECT COALESCE(` +
          `array_agg(btbl.${ident(targetSlug)} ORDER BY btbl.${ident(targetSlug)}) FILTER (WHERE btbl.${ident(targetSlug)} IS NOT NULL), ` +
          `'{}'::text[]) ` +
          `FROM ${ident(POSTGRES_SCHEMA)}.${ident(jn)} j ` +
          `JOIN ${ident(POSTGRES_SCHEMA)}.${ident(b)} btbl ON btbl.nocopk = j.${ident(b + '_id')} ` +
          `WHERE j.${ident(a + '_id')} = base.nocopk) AS ${outCol}`;

        exprs.push(expr);
      }

      csql += `CREATE VIEW ${ident(POSTGRES_SCHEMA)}.${ident('vc_' + a)} AS\n`;
      csql += `SELECT base.*,\n  ${exprs.join(',\n  ')}\n`;
      csql += `FROM ${ident(POSTGRES_SCHEMA)}.${ident('v_' + a)} base;\n\n`;
    }

    csql += `COMMIT;\n`;
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '004_computed_views.sql'), csql, 'utf8');
  }

  // 010_load.sql + csv/*.csv (relational)
  if (AIRTABLE_EXPORT_DIR && fs.existsSync(AIRTABLE_EXPORT_DIR)) {
    const csvDir = path.join(POSTGRES_OUT_DIR, 'csv');
    ensureDir(csvDir);

    const loadSql = [];
    loadSql.push(sqlHeader());
    loadSql.push('\\set ON_ERROR_STOP on\nBEGIN;\n');
    loadSql.push(`SET search_path TO ${ident(POSTGRES_SCHEMA)};\n`);

    // Base tables: load only stored non-link fields
    for (const t of tables) {
      const tableName = t.name;
      const tableSlug = slug(tableName);
      const fp = findTableFile(AIRTABLE_EXPORT_DIR, tableName);
      if (!fp) continue;

      const data = readJson(fp);
      const rowsRaw = Array.isArray(data) ? data : (data.records || data.rows || []);
      if (!Array.isArray(rowsRaw) || rowsRaw.length === 0) continue;

      const storedFields = (t.fields || []).filter(f =>
        !isComputed(f) &&
        f.type !== 'multipleRecordLinks' &&
        f.type !== 'singleRecordLink' &&
        f.type !== 'button'
      );
      const storedColSlugs = storedFields.map(f => slug(f.name)).filter(Boolean);
      const cols = ['airtable_id', ...storedColSlugs];

      const rows = rowsRaw.map(r => {
        const out = {};
        const airtableId = r.id || r.airtable_id || r.recordId || null;
        if (!airtableId) return null;
        out.airtable_id = airtableId;
        const fieldsObj = (r.fields && typeof r.fields === 'object') ? r.fields : r;

        for (const f of storedFields) {
          const kk = slug(f.name);
          let v = fieldsObj[f.name];
          if (v === undefined) continue;
          if (v && typeof v === 'object') v = JSON.stringify(v);
          out[kk] = v;
        }
        for (const c of cols) if (!(c in out)) out[c] = '';
        return out;
      }).filter(Boolean);

      if (!rows.length) continue;

      const csvPath = writeCsv(csvDir, tableSlug, cols, rows);
      loadSql.push(`\\copy ${ident(tableSlug)}(${cols.map(ident).join(',')}) FROM '${path.relative(POSTGRES_OUT_DIR, csvPath).replace(/\\/g,'/')}' WITH (FORMAT csv, HEADER true);\n`);
    }

    // Junctions: export link pairs and resolve airtable_id -> nocopk during insert
    for (const t of tables) {
      const aName = t.name;
      const a = slug(aName);
      const fp = findTableFile(AIRTABLE_EXPORT_DIR, aName);
      if (!fp) continue;

      const data = readJson(fp);
      const rowsRaw = Array.isArray(data) ? data : (data.records || data.rows || []);
      if (!Array.isArray(rowsRaw) || rowsRaw.length === 0) continue;

      const linkFields = (t.fields || []).filter(f => f.type === 'multipleRecordLinks' && f.options && f.options.linkedTableId);
      for (const f of linkFields) {
        const other = tableById(schema, f.options.linkedTableId);
        if (!other) continue;
        const b = slug(other.name);

        const jn = `_m2m_${a}_${b}_${slug(f.name) || 'link'}`;
        const rawName = `${jn}__raw`;
        const cols = ['a_airtable_id', 'b_airtable_id'];
        const aCol = `${a}_id`;
        const bCol = (a === b) ? `${b}1_id` : `${b}_id`;

        const jrows = [];
        for (const r of rowsRaw) {
          const aId = r.id || r.airtable_id || r.recordId || null;
          if (!aId) continue;
          const fieldsObj = (r.fields && typeof r.fields === 'object') ? r.fields : r;
          const linked = fieldsObj[f.name];
          if (!linked) continue;
          const linkedIds = Array.isArray(linked) ? linked : [linked];
          for (const bId of linkedIds) {
            if (!bId) continue;
            jrows.push({ a_airtable_id: aId, b_airtable_id: bId });
          }
        }
        if (!jrows.length) continue;

        const csvPath = writeCsv(csvDir, rawName, cols, jrows);
        loadSql.push(`\n-- Link field: ${aName}.${f.name} -> ${other.name}\n`);
        loadSql.push(`CREATE TEMP TABLE ${ident(rawName)}(${ident('a_airtable_id')} text, ${ident('b_airtable_id')} text);\n`);
        loadSql.push(`\\copy ${ident(rawName)}(${cols.map(ident).join(',')}) FROM '${path.relative(POSTGRES_OUT_DIR, csvPath).replace(/\\/g,'/')}' WITH (FORMAT csv, HEADER true);\n`);
        loadSql.push(`INSERT INTO ${ident(jn)}(${ident(aCol)}, ${ident(bCol)})\n`);
        loadSql.push(`SELECT a.nocopk, b.nocopk\nFROM ${ident(rawName)} r\nJOIN ${ident(a)} a ON a.airtable_id = r.a_airtable_id\nJOIN ${ident(b)} b ON b.airtable_id = r.b_airtable_id;\n`);
        loadSql.push(`DROP TABLE ${ident(rawName)};\n`);
      }
    }

    loadSql.push('COMMIT;\n');
    fs.writeFileSync(path.join(POSTGRES_OUT_DIR, '010_load.sql'), loadSql.join(''), 'utf8');
  }

  console.log('[OK] Wrote Postgres artifacts to:', POSTGRES_OUT_DIR);
  console.log(' - 001_tables.sql');
  console.log(' - 002_links.sql');
  if (CREATE_VIEWS) console.log(' - 003_views.sql');
  console.log(' - 004_computed_views.sql (lookup/rollup scaffolding)');
  if (AIRTABLE_EXPORT_DIR) console.log(' - 010_load.sql + csv/*.csv (relational)');
}

main();
